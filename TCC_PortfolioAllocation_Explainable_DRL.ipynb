{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicardoFagundes123/PortfolioAllocation/blob/main/TCC_PortfolioAllocation_Explainable_DRL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv3IDvrobU37"
      },
      "source": [
        "# Explainable Deep Reinforcement Learning for Portfolio Managemnet: an Emprical Approach.\n",
        "\n",
        "Tutorials to use FinRL Library to perform explainable portfolio allocation in one [Jupyter Notebook](https://colab.research.google.com/drive/117v2qWo-qPC7OPd7paY1wYkOUywU_DWZ?usp=sharing)\n",
        "\n",
        "* This tutorial is based on the [portfolio allocation tutorial](https://github.com/AI4Finance-Foundation/FinRL/blob/master/FinRL_portfolio_allocation_NeurIPS_2020.ipynb) in FinRL Library.\n",
        "* This blog is based on our paper: Explainable Deep Reinforcement Learning for Portfolio Managemnet: an Emprical Approach\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHCfEiTA80V"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUmLTmoQA7_w"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12v1i0jVkg48"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L63HKnWvkirx"
      },
      "source": [
        "This problem is to empirically explain the trading performance of DRL agents for the portfolio management task.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed portfolio weights that the agent interacts with the\n",
        "environment. Each element in the portfolio weights is between [0, 1].\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The logorithmic rate of portfolio return when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = ln(v'/v), where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes  an agent’s perception of a market.  Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "We use Yahoo Finance API as the data source.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_emqQCCklVt"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCcCalAknGn"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pT8a0fvhA_TW",
        "outputId": "dfd4df7a-bfde-4d9b-ae5a-ec44d6924520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting plotly==4.4.1\n",
            "  Downloading plotly-4.4.1-py2.py3-none-any.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 12.2 MB/s \n",
            "\u001b[?25hCollecting retrying>=1.3.3\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly==4.4.1) (1.15.0)\n",
            "Building wheels for collected packages: retrying\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11447 sha256=12eb5a051b10d54890348ac44092b80c1cfc7d768598b3f918cf34b9b82e8328\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
            "Successfully built retrying\n",
            "Installing collected packages: retrying, plotly\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.5.0\n",
            "    Uninstalling plotly-5.5.0:\n",
            "      Successfully uninstalled plotly-5.5.0\n",
            "Successfully installed plotly-4.4.1 retrying-1.3.3\n",
            "--2022-10-25 01:18:22--  https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221025%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221025T011822Z&X-Amz-Expires=300&X-Amz-Signature=a22b4962c9d777130808e2716c2e4305120d3dcde5e56c1717c140b3ae76f89b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=99037241&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-10-25 01:18:23--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/99037241/9dc3a580-286a-11e9-8a21-4312b7c8a512?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221025%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221025T011822Z&X-Amz-Expires=300&X-Amz-Signature=a22b4962c9d777130808e2716c2e4305120d3dcde5e56c1717c140b3ae76f89b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=99037241&response-content-disposition=attachment%3B%20filename%3Dorca-1.2.1-x86_64.AppImage&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51607939 (49M) [application/octet-stream]\n",
            "Saving to: ‘/usr/local/bin/orca’\n",
            "\n",
            "/usr/local/bin/orca 100%[===================>]  49.22M  14.7MB/s    in 3.8s    \n",
            "\n",
            "2022-10-25 01:18:27 (12.9 MB/s) - ‘/usr/local/bin/orca’ saved [51607939/51607939]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2\n",
            "  libgail-common libgail18 libgtk2.0-bin libgtk2.0-common\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  gconf-service gconf-service-backend gconf2-common libdbus-glib-1-2\n",
            "  libgail-common libgail18 libgconf-2-4 libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common xvfb\n",
            "0 upgraded, 11 newly installed, 0 to remove and 27 not upgraded.\n",
            "Need to get 3,716 kB of archives.\n",
            "After this operation, 17.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libdbus-glib-1-2 amd64 0.110-2 [58.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf2-common all 3.2.6-4ubuntu1 [700 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgconf-2-4 amd64 3.2.6-4ubuntu1 [84.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf-service-backend amd64 3.2.6-4ubuntu1 [58.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gconf-service amd64 3.2.6-4ubuntu1 [2,036 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.11 [785 kB]\n",
            "Fetched 3,716 kB in 0s (23.4 MB/s)\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libdbus-glib-1-2_0.110-2_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.110-2) ...\n",
            "Selecting previously unselected package gconf2-common.\n",
            "Preparing to unpack .../01-gconf2-common_3.2.6-4ubuntu1_all.deb ...\n",
            "Unpacking gconf2-common (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package libgconf-2-4:amd64.\n",
            "Preparing to unpack .../02-libgconf-2-4_3.2.6-4ubuntu1_amd64.deb ...\n",
            "Unpacking libgconf-2-4:amd64 (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package gconf-service-backend.\n",
            "Preparing to unpack .../03-gconf-service-backend_3.2.6-4ubuntu1_amd64.deb ...\n",
            "Unpacking gconf-service-backend (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package gconf-service.\n",
            "Preparing to unpack .../04-gconf-service_3.2.6-4ubuntu1_amd64.deb ...\n",
            "Unpacking gconf-service (3.2.6-4ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "Preparing to unpack .../05-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../06-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../07-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../08-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../09-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../10-xvfb_2%3a1.19.6-1ubuntu4.11_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up gconf2-common (3.2.6-4ubuntu1) ...\n",
            "\n",
            "Creating config file /etc/gconf/2/path with new version\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.110-2) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up libgconf-2-4:amd64 (3.2.6-4ubuntu1) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up gconf-service-backend (3.2.6-4ubuntu1) ...\n",
            "Setting up gconf-service (3.2.6-4ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
            "  Cloning https://github.com/AI4Finance-LLC/FinRL-Library.git to /tmp/pip-req-build-0rw8a5j_\n",
            "  Running command git clone -q https://github.com/AI4Finance-LLC/FinRL-Library.git /tmp/pip-req-build-0rw8a5j_\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-_xjoevom/pyfolio_7e02a8382ecf427d9c5d39d55f17df3d\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-_xjoevom/pyfolio_7e02a8382ecf427d9c5d39d55f17df3d\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-_xjoevom/elegantrl_888aa696c70f4a099d0f115b3c788979\n",
            "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-_xjoevom/elegantrl_888aa696c70f4a099d0f115b3c788979\n",
            "Collecting alpaca_trade_api>=2.1.0\n",
            "  Downloading alpaca_trade_api-2.3.0-py3-none-any.whl (33 kB)\n",
            "Collecting ccxt==1.66.32\n",
            "  Downloading ccxt-1.66.32-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 22.8 MB/s \n",
            "\u001b[?25hCollecting elegantrl\n",
            "  Downloading elegantrl-0.3.3-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting exchange_calendars==3.6.3\n",
            "  Downloading exchange_calendars-3.6.3.tar.gz (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (4.13.0)\n",
            "Collecting jqdatasdk\n",
            "  Downloading jqdatasdk-1.8.11-py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 65.8 MB/s \n",
            "\u001b[?25hCollecting lz4\n",
            "  Downloading lz4-4.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.3.5)\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 72.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.6.4)\n",
            "Collecting ray[default]\n",
            "  Downloading ray-2.0.1-cp37-cp37m-manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.5 MB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.0.2)\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 58.5 MB/s \n",
            "\u001b[?25hCollecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.6.2-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 72.3 MB/s \n",
            "\u001b[?25hCollecting stockstats>=0.4.0\n",
            "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 65.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.37.1)\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.1.2-py3-none-any.whl (13 kB)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.81-py2.py3-none-any.whl (29 kB)\n",
            "Collecting pybullet\n",
            "  Downloading pybullet-3.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (91.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 91.7 MB 36 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (1.12.1+cu113)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (4.6.0.66)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (7.9.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2022.4)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.7.3)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.11.2)\n",
            "Collecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2022.9.24)\n",
            "Collecting cryptography>=2.6.1\n",
            "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.8 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (3.8.3)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2.23.0)\n",
            "Collecting yarl==1.7.2\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.0 MB/s \n",
            "\u001b[?25hCollecting aiodns>=1.1.1\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Collecting pyluach\n",
            "  Downloading pyluach-2.0.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.8.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata==4.13.0->finrl==0.3.5) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata==4.13.0->finrl==0.3.5) (3.9.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (2.10)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (6.0.2)\n",
            "Collecting pycares>=4.0.0\n",
            "  Downloading pycares-4.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[K     |████████████████████████████████| 288 kB 68.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (2.1.1)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0)\n",
            "Collecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.7/dist-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.24.3)\n",
            "Collecting aiohttp>=3.8\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 49.0 MB/s \n",
            "\u001b[?25hCollecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting msgpack==1.0.3\n",
            "  Downloading msgpack-1.0.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[K     |████████████████████████████████| 299 kB 71.9 MB/s \n",
            "\u001b[?25hCollecting websockets<11,>=9.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api>=2.1.0->finrl==0.3.5) (21.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (2.21)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (1.5.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (0.0.8)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.9.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->ccxt==1.66.32->finrl==0.3.5) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.2.0)\n",
            "Collecting pymysql>=0.7.6\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting thriftpy2>=0.3.9\n",
            "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 64.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.5) (1.4.41)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (1.1.3.post0)\n",
            "Collecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.16.5-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 54.2 MB/s \n",
            "\u001b[?25hCollecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from pre-commit->finrl==0.3.5) (0.10.2)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.7-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2.4\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.5\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[K     |████████████████████████████████| 468 kB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.4.1 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.5) (3.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.4.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (8.14.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (7.1.2)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (3.17.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (4.3.3)\n",
            "Collecting grpcio<=1.43.0,>=1.32.0\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 59.5 MB/s \n",
            "\u001b[?25hCollecting prometheus-client<0.14.0,>=0.7.1\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (1.9.2)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 54.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (5.2.1)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 68.7 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0.tar.gz (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.0 MB/s \n",
            "\u001b[?25hCollecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting psutil>=5.6.0\n",
            "  Downloading psutil-5.9.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 63.5 MB/s \n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (0.18.1)\n",
            "Collecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.5) (1.31.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.56.4)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.2.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.4.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.8.10)\n",
            "Collecting gym>=0.17\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (4.64.1)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Collecting rich\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 65.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (2.9.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (7.1.2)\n",
            "Collecting ale-py==0.7.4\n",
            "  Downloading ale_py-0.7.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 55.8 MB/s \n",
            "\u001b[?25hCollecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->stable-baselines3[extra]->finrl==0.3.5) (3.2.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 57.6 MB/s \n",
            "\u001b[?25hCollecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.5) (0.0.11)\n",
            "Collecting requests>=2.18.4\n",
            "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "Building wheels for collected packages: finrl, elegantrl, pyfolio, exchange-calendars, empyrical, gputil, thriftpy2, gpustat, gym, AutoROM.accept-rom-license\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.5-py3-none-any.whl size=2737287 sha256=3ad979e522f09df9bc5e88db6eb44b15f312d83719b551d65c106ac7a434881b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t12laeay/wheels/17/ff/bd/1bc602a0352762b0b24041b88536d803ae343ed0a711fcf55e\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=elegantrl-0.3.3-py3-none-any.whl size=347937 sha256=fcb90fb189bae71e75318bc48c7ac663c5de2cb19a4cbfa7a51a437336353ee4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t12laeay/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75774 sha256=05a7b26be0a6ae5122f9e0834ea28fa0903ebc4b2119944952315effd610a1dc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t12laeay/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
            "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exchange-calendars: filename=exchange_calendars-3.6.3-py3-none-any.whl size=182636 sha256=7e333c552bee982e69b2cde8a99962f8fbd1509315476205fb541c0209ba61ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/a3/19/b4611514d34ffd61d13aef10fefc2dcaf3754145121ceba647\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39780 sha256=642be6f36ead76764a5887faef7216e9a50ff73a9ea55e5660547511e06220f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=8f2985e8033ea93bd4bb3857deef109458a9d1a7ef6eac953d2eeb21bd7a1d65\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=953339 sha256=ea163993a77408691c801d76de0bbd2f6c0f69ffd17d2012cc122a18ef1693ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0-py3-none-any.whl size=19889 sha256=9b3dfe379e55335b0772d0d15489e8edd99f5153a1b66c3a147f7cf8179d0090\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/31/5c/eb69af6e2285e7d6ec8d7dc26435be7c81c6ad22c45efdcca7\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616826 sha256=ecf80053fd042f102ed9d7cd2cbe9934231967c83bf4f217a8e051858a15bf57\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=245c67edb2977871173d62c847bcbe234994a6663321f19c0f9fb6662ecd6f69\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built finrl elegantrl pyfolio exchange-calendars empyrical gputil thriftpy2 gpustat gym AutoROM.accept-rom-license\n",
            "Installing collected packages: setuptools, requests, yarl, platformdirs, distlib, virtualenv, pycares, psutil, ply, opencensus-context, nvidia-ml-py, msgpack, jedi, gym, grpcio, commonmark, blessed, AutoROM.accept-rom-license, autorom, aiohttp, websockets, websocket-client, thriftpy2, tensorboardX, stable-baselines3, rich, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, prometheus-client, opencensus, nodeenv, mock, identify, gpustat, empyrical, deprecation, cryptography, colorful, cfgv, box2d-py, ale-py, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.8.1\n",
            "    Uninstalling yarl-1.8.1:\n",
            "      Successfully uninstalled yarl-1.8.1\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.4\n",
            "    Uninstalling msgpack-1.0.4:\n",
            "      Successfully uninstalled msgpack-1.0.4\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.49.1\n",
            "    Uninstalling grpcio-1.49.1:\n",
            "      Successfully uninstalled grpcio-1.49.1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.8.3\n",
            "    Uninstalling aiohttp-3.8.3:\n",
            "      Successfully uninstalled aiohttp-3.8.3\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 aiodns-3.0.0 aiohttp-3.8.1 aiohttp-cors-0.7.0 ale-py-0.7.4 alpaca-trade-api-2.3.0 autorom-0.4.2 blessed-1.19.1 box2d-py-2.3.8 ccxt-1.66.32 cfgv-3.3.1 colorful-0.5.4 commonmark-0.9.1 cryptography-38.0.1 deprecation-2.1.0 distlib-0.3.6 elegantrl-0.3.3 empyrical-0.5.5 exchange-calendars-3.6.3 finrl-0.3.5 gpustat-1.0.0 gputil-1.4.0 grpcio-1.43.0 gym-0.21.0 identify-2.5.7 jedi-0.18.1 jqdatasdk-1.8.11 lz4-4.0.2 mock-4.0.3 msgpack-1.0.3 nodeenv-1.7.0 nvidia-ml-py-11.495.46 opencensus-0.11.0 opencensus-context-0.1.3 platformdirs-2.5.2 ply-3.11 pre-commit-2.20.0 prometheus-client-0.13.1 psutil-5.9.3 psycopg2-binary-2.9.4 py-spy-0.3.14 pybullet-3.2.5 pycares-4.2.2 pyfolio-0.9.2+75.g4b901f6 pyluach-2.0.2 pymysql-1.0.2 ray-2.0.1 requests-2.28.1 rich-12.6.0 setuptools-59.5.0 stable-baselines3-1.6.2 stockstats-0.4.1 tensorboardX-2.5.1 thriftpy2-0.4.14 virtualenv-20.16.5 websocket-client-1.4.1 websockets-10.3 wrds-3.1.2 yarl-1.7.2 yfinance-0.1.81\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPortfolioOpt\n",
            "  Downloading pyportfolioopt-1.5.2-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.3.5)\n",
            "Requirement already satisfied: scipy<2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.7.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.21.6)\n",
            "Requirement already satisfied: cvxpy<2.0.0,>=1.1.10 in /usr/local/lib/python3.7/dist-packages (from PyPortfolioOpt) (1.2.1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (3.2.0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (2.0.10)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy<2.0.0,>=1.1.10->PyPortfolioOpt) (0.1.5.post2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->PyPortfolioOpt) (2022.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->PyPortfolioOpt) (1.15.0)\n",
            "Installing collected packages: PyPortfolioOpt\n",
            "Successfully installed PyPortfolioOpt-1.5.2\n"
          ]
        }
      ],
      "source": [
        "## install finrl library\n",
        "!pip install plotly==4.4.1\n",
        "!wget https://github.com/plotly/orca/releases/download/v1.2.1/orca-1.2.1-x86_64.AppImage -O /usr/local/bin/orca\n",
        "!chmod +x /usr/local/bin/orca\n",
        "!apt-get install xvfb libgtk2.0-0 libgconf-2-4\n",
        "!pip install git+https://github.com/AI4Finance-LLC/FinRL-Library.git\n",
        "!pip install PyPortfolioOpt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4HEDAMZpfpd"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2568cp5bU38"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them. \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNmvYN9YbU4B"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcCpdTE9z0WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d4e866-668b-4619-a427-f53a2eb5082c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent\n",
        "from stable_baselines3.common.logger import configure\n",
        "from finrl.meta.data_processor import DataProcessor\n",
        "\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "CXuOuIoHyB8t"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8bBq7nsBCfF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl import config\n",
        "from finrl import config_tickers\n",
        "\n",
        "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
        "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
        "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
        "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
        "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
        "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
        "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
        "    os.makedirs(\"./\" + config.RESULTS_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slBria_QbU4F"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-EVc4VqymIR"
      },
      "outputs": [],
      "source": [
        "lista = [\"VALE3.SA\", \"PETR4.SA\", \"ITUB4.SA\", \"BBDC4.SA\", \"PETR3.SA\", \"B3SA3.SA\", \"ABEV3.SA\", \"JBSS3.SA\", \"BBAS3.SA\", \"WEGE3.SA\"]\n",
        "lista += [\"ITSA4.SA\", \"RENT3.SA\", \"GGBR4.SA\", \"EQTL3.SA\", \"CSAN3.SA\", \"LREN3.SA\", \"BBDC3.SA\", \"RADL3.SA\", \"VIVT3.SA\", \"ENEV3.SA\"]\n",
        "start_date = \"2011-06-01\"\n",
        "mid_date = \"2021-06-01\"\n",
        "end_date = \"2022-06-01\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEwzMkFHbU4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8825ff23-1e52-497c-a5fd-d7dd89639637"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (54580, 8)\n"
          ]
        }
      ],
      "source": [
        "df = YahooDownloader(start_date = start_date,\n",
        "                     end_date = end_date,\n",
        "                     ticker_list = lista).fetch_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9UwKwzRbU4l"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5h8RbeBHMDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8582fcdb-4f30-4a84-9585-9f8d47b7e71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(\n",
        "                    use_technical_indicator=True,\n",
        "                    use_turbulence=False,\n",
        "                    user_defined_feature = False)\n",
        "\n",
        "df = fe.preprocess_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz9K2vul6RmK"
      },
      "source": [
        "## Add covariance matrix as states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHVFkbWJ9_Rj"
      },
      "outputs": [],
      "source": [
        "# add covariance matrix as states\n",
        "df=df.sort_values(['date','tic'],ignore_index=True)\n",
        "df.index = df.date.factorize()[0]\n",
        "\n",
        "cov_list = []\n",
        "return_list = []\n",
        "\n",
        "# look back is one year\n",
        "lookback=252\n",
        "for i in range(lookback,len(df.index.unique())):\n",
        "  data_lookback = df.loc[i-lookback:i,:]\n",
        "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
        "  return_lookback = price_lookback.pct_change().dropna()\n",
        "  return_list.append(return_lookback)\n",
        "\n",
        "  covs = return_lookback.cov().values \n",
        "  cov_list.append(covs)\n",
        "\n",
        "  \n",
        "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "df = df.merge(df_cov, on='date')\n",
        "df = df.sort_values(['date','tic']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UooHj1OgbU4v"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed portfolio weights that the agent interacts with the environment. Each element in the portfolio weights vector is non-negative and no more than 100%. Also, the sum of elements in each portfolio weight should equal to 100%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQnmN1qdk88I"
      },
      "source": [
        "## Training data split: 2009-01-01 to 2020-06-30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrPxgv4eBQ_R"
      },
      "outputs": [],
      "source": [
        "train = data_split(df, start_date, mid_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQIKi7rxgbmj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1f344cc-a431-46f5-b0bd-3460d731cdaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date        open        high         low       close      volume  \\\n",
              "0  2012-06-05   11.916784   11.916784   11.722804    8.210924    607061.0   \n",
              "0  2012-06-05    3.176666    3.263333    3.170000    2.107632  25761600.0   \n",
              "0  2012-06-05   19.469999   19.650000   18.799999    9.660904   5817900.0   \n",
              "0  2012-06-05    8.739661    8.739661    8.402839    5.584674   1732899.0   \n",
              "0  2012-06-05   10.459160   10.523305   10.156254    6.536068  16891635.0   \n",
              "0  2012-06-05    6.507812    6.632236    6.507812    4.680905   2492061.0   \n",
              "0  2012-06-05  154.689590  156.268051  148.561432  149.768494    149099.0   \n",
              "0  2012-06-05    2.986679    3.026501    2.966768    2.502494    390734.0   \n",
              "0  2012-06-05   16.250000   16.530001   15.950000   11.677818   7588900.0   \n",
              "0  2012-06-05    4.890393    4.925159    4.768713    2.823221  13930402.0   \n",
              "0  2012-06-05   12.886187   12.954488   12.612981    8.285101  14122342.0   \n",
              "0  2012-06-05    5.560000    5.680000    5.370000    4.227033   4560800.0   \n",
              "0  2012-06-05    9.314158    9.489619    9.168214    7.647001   3758346.0   \n",
              "0  2012-06-05   20.000000   20.180000   19.590000    9.901456   5008400.0   \n",
              "0  2012-06-05   19.209999   19.320000   18.740000    8.711926  20669600.0   \n",
              "0  2012-06-05    3.742000    3.816000    3.696000    3.460211   6829000.0   \n",
              "0  2012-06-05    9.292013    9.542526    9.185473    6.772543   3015150.0   \n",
              "0  2012-06-05   37.000000   37.250000   36.470001   20.544390         0.0   \n",
              "0  2012-06-05   44.000000   44.000000   43.619999   20.678814      9900.0   \n",
              "0  2012-06-05    2.973372    2.988165    2.934911    2.401510   2784444.0   \n",
              "\n",
              "        tic  day      macd     boll_ub     boll_lb     rsi_30      cci_30  \\\n",
              "0  ABEV3.SA    1 -0.192321    9.287138    8.223361  40.647534 -158.089461   \n",
              "0  B3SA3.SA    1 -0.057104    2.239439    1.999336  42.011134  -45.260385   \n",
              "0  BBAS3.SA    1 -0.504616   11.595399    9.586816  32.363936 -124.365204   \n",
              "0  BBDC3.SA    1 -0.057727    5.909775    5.399636  42.743850  -43.253991   \n",
              "0  BBDC4.SA    1 -0.052764    6.882259    6.217056  44.010082  -21.074773   \n",
              "0  CSAN3.SA    1 -0.132715    5.263828    4.424561  42.629531  -76.414303   \n",
              "0  ENEV3.SA    1 -7.513182  199.437348  138.987390  38.875702 -122.621552   \n",
              "0  EQTL3.SA    1  0.036772    2.553279    2.362970  58.995534   82.821755   \n",
              "0  GGBR4.SA    1 -0.194037   12.216379   11.326129  44.998984  -38.346927   \n",
              "0  ITSA4.SA    1 -0.065139    3.027042    2.754396  39.589615  -81.476880   \n",
              "0  ITUB4.SA    1 -0.180189    8.794881    8.096449  38.499688  -81.727049   \n",
              "0  JBSS3.SA    1 -0.346570    5.721885    3.786224  37.513330  -97.704881   \n",
              "0  LREN3.SA    1 -0.128010    8.631506    7.471175  44.218486 -113.019963   \n",
              "0  PETR3.SA    1 -0.269144   10.459249    9.554339  40.779704  -54.915745   \n",
              "0  PETR4.SA    1 -0.231410    9.215684    8.410190  41.139328  -57.401203   \n",
              "0  RADL3.SA    1 -0.036516    3.787477    3.132766  53.818737  -48.439870   \n",
              "0  RENT3.SA    1 -0.019501    6.860302    6.015596  52.173430   76.266817   \n",
              "0  VALE3.SA    1 -0.565324   22.247736   19.670845  40.582172  -71.249572   \n",
              "0  VIVT3.SA    1 -0.560063   23.568125   20.118588  41.313782 -135.274188   \n",
              "0  WEGE3.SA    1  0.004863    2.497084    2.385461  49.398034  -80.988473   \n",
              "\n",
              "       dx_30  close_30_sma  close_60_sma  \\\n",
              "0  61.483524      8.961126      8.971092   \n",
              "0  12.300316      2.198522      2.359554   \n",
              "0  52.179832     11.006380     12.172221   \n",
              "0  19.336663      5.742033      6.034262   \n",
              "0  13.904444      6.653079      6.937155   \n",
              "0  27.285859      4.980362      5.159259   \n",
              "0  42.700918    175.358506    177.438404   \n",
              "0  16.908803      2.419517      2.323336   \n",
              "0  12.920184     12.065512     12.595157   \n",
              "0  17.865437      2.942847      3.234244   \n",
              "0  19.277358      8.573704      9.493645   \n",
              "0  45.536563      5.091054      5.556286   \n",
              "0  27.200931      8.138826      8.253281   \n",
              "0  17.852437     10.346821     11.112810   \n",
              "0  11.167455      9.083429      9.781968   \n",
              "0   1.218313      3.536562      3.387031   \n",
              "0  16.973351      6.585875      6.841913   \n",
              "0  26.254835     21.819530     22.507051   \n",
              "0  44.660532     22.197941     22.843590   \n",
              "0   6.180105      2.437056      2.414865   \n",
              "\n",
              "                                            cov_list  \\\n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "0  [[0.00018903795517714915, 9.757488254570043e-0...   \n",
              "\n",
              "                                         return_list  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  \n",
              "0  tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e055ea77-96a4-4f81-aeee-a2483c890899\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>11.916784</td>\n",
              "      <td>11.916784</td>\n",
              "      <td>11.722804</td>\n",
              "      <td>8.210924</td>\n",
              "      <td>607061.0</td>\n",
              "      <td>ABEV3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.192321</td>\n",
              "      <td>9.287138</td>\n",
              "      <td>8.223361</td>\n",
              "      <td>40.647534</td>\n",
              "      <td>-158.089461</td>\n",
              "      <td>61.483524</td>\n",
              "      <td>8.961126</td>\n",
              "      <td>8.971092</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>3.176666</td>\n",
              "      <td>3.263333</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>2.107632</td>\n",
              "      <td>25761600.0</td>\n",
              "      <td>B3SA3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.057104</td>\n",
              "      <td>2.239439</td>\n",
              "      <td>1.999336</td>\n",
              "      <td>42.011134</td>\n",
              "      <td>-45.260385</td>\n",
              "      <td>12.300316</td>\n",
              "      <td>2.198522</td>\n",
              "      <td>2.359554</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>19.469999</td>\n",
              "      <td>19.650000</td>\n",
              "      <td>18.799999</td>\n",
              "      <td>9.660904</td>\n",
              "      <td>5817900.0</td>\n",
              "      <td>BBAS3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.504616</td>\n",
              "      <td>11.595399</td>\n",
              "      <td>9.586816</td>\n",
              "      <td>32.363936</td>\n",
              "      <td>-124.365204</td>\n",
              "      <td>52.179832</td>\n",
              "      <td>11.006380</td>\n",
              "      <td>12.172221</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>8.739661</td>\n",
              "      <td>8.739661</td>\n",
              "      <td>8.402839</td>\n",
              "      <td>5.584674</td>\n",
              "      <td>1732899.0</td>\n",
              "      <td>BBDC3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.057727</td>\n",
              "      <td>5.909775</td>\n",
              "      <td>5.399636</td>\n",
              "      <td>42.743850</td>\n",
              "      <td>-43.253991</td>\n",
              "      <td>19.336663</td>\n",
              "      <td>5.742033</td>\n",
              "      <td>6.034262</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>10.459160</td>\n",
              "      <td>10.523305</td>\n",
              "      <td>10.156254</td>\n",
              "      <td>6.536068</td>\n",
              "      <td>16891635.0</td>\n",
              "      <td>BBDC4.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.052764</td>\n",
              "      <td>6.882259</td>\n",
              "      <td>6.217056</td>\n",
              "      <td>44.010082</td>\n",
              "      <td>-21.074773</td>\n",
              "      <td>13.904444</td>\n",
              "      <td>6.653079</td>\n",
              "      <td>6.937155</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>6.507812</td>\n",
              "      <td>6.632236</td>\n",
              "      <td>6.507812</td>\n",
              "      <td>4.680905</td>\n",
              "      <td>2492061.0</td>\n",
              "      <td>CSAN3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.132715</td>\n",
              "      <td>5.263828</td>\n",
              "      <td>4.424561</td>\n",
              "      <td>42.629531</td>\n",
              "      <td>-76.414303</td>\n",
              "      <td>27.285859</td>\n",
              "      <td>4.980362</td>\n",
              "      <td>5.159259</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>154.689590</td>\n",
              "      <td>156.268051</td>\n",
              "      <td>148.561432</td>\n",
              "      <td>149.768494</td>\n",
              "      <td>149099.0</td>\n",
              "      <td>ENEV3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-7.513182</td>\n",
              "      <td>199.437348</td>\n",
              "      <td>138.987390</td>\n",
              "      <td>38.875702</td>\n",
              "      <td>-122.621552</td>\n",
              "      <td>42.700918</td>\n",
              "      <td>175.358506</td>\n",
              "      <td>177.438404</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>2.986679</td>\n",
              "      <td>3.026501</td>\n",
              "      <td>2.966768</td>\n",
              "      <td>2.502494</td>\n",
              "      <td>390734.0</td>\n",
              "      <td>EQTL3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>0.036772</td>\n",
              "      <td>2.553279</td>\n",
              "      <td>2.362970</td>\n",
              "      <td>58.995534</td>\n",
              "      <td>82.821755</td>\n",
              "      <td>16.908803</td>\n",
              "      <td>2.419517</td>\n",
              "      <td>2.323336</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>16.250000</td>\n",
              "      <td>16.530001</td>\n",
              "      <td>15.950000</td>\n",
              "      <td>11.677818</td>\n",
              "      <td>7588900.0</td>\n",
              "      <td>GGBR4.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.194037</td>\n",
              "      <td>12.216379</td>\n",
              "      <td>11.326129</td>\n",
              "      <td>44.998984</td>\n",
              "      <td>-38.346927</td>\n",
              "      <td>12.920184</td>\n",
              "      <td>12.065512</td>\n",
              "      <td>12.595157</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>4.890393</td>\n",
              "      <td>4.925159</td>\n",
              "      <td>4.768713</td>\n",
              "      <td>2.823221</td>\n",
              "      <td>13930402.0</td>\n",
              "      <td>ITSA4.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.065139</td>\n",
              "      <td>3.027042</td>\n",
              "      <td>2.754396</td>\n",
              "      <td>39.589615</td>\n",
              "      <td>-81.476880</td>\n",
              "      <td>17.865437</td>\n",
              "      <td>2.942847</td>\n",
              "      <td>3.234244</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>12.886187</td>\n",
              "      <td>12.954488</td>\n",
              "      <td>12.612981</td>\n",
              "      <td>8.285101</td>\n",
              "      <td>14122342.0</td>\n",
              "      <td>ITUB4.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.180189</td>\n",
              "      <td>8.794881</td>\n",
              "      <td>8.096449</td>\n",
              "      <td>38.499688</td>\n",
              "      <td>-81.727049</td>\n",
              "      <td>19.277358</td>\n",
              "      <td>8.573704</td>\n",
              "      <td>9.493645</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>5.560000</td>\n",
              "      <td>5.680000</td>\n",
              "      <td>5.370000</td>\n",
              "      <td>4.227033</td>\n",
              "      <td>4560800.0</td>\n",
              "      <td>JBSS3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.346570</td>\n",
              "      <td>5.721885</td>\n",
              "      <td>3.786224</td>\n",
              "      <td>37.513330</td>\n",
              "      <td>-97.704881</td>\n",
              "      <td>45.536563</td>\n",
              "      <td>5.091054</td>\n",
              "      <td>5.556286</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>9.314158</td>\n",
              "      <td>9.489619</td>\n",
              "      <td>9.168214</td>\n",
              "      <td>7.647001</td>\n",
              "      <td>3758346.0</td>\n",
              "      <td>LREN3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.128010</td>\n",
              "      <td>8.631506</td>\n",
              "      <td>7.471175</td>\n",
              "      <td>44.218486</td>\n",
              "      <td>-113.019963</td>\n",
              "      <td>27.200931</td>\n",
              "      <td>8.138826</td>\n",
              "      <td>8.253281</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.180000</td>\n",
              "      <td>19.590000</td>\n",
              "      <td>9.901456</td>\n",
              "      <td>5008400.0</td>\n",
              "      <td>PETR3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.269144</td>\n",
              "      <td>10.459249</td>\n",
              "      <td>9.554339</td>\n",
              "      <td>40.779704</td>\n",
              "      <td>-54.915745</td>\n",
              "      <td>17.852437</td>\n",
              "      <td>10.346821</td>\n",
              "      <td>11.112810</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>19.209999</td>\n",
              "      <td>19.320000</td>\n",
              "      <td>18.740000</td>\n",
              "      <td>8.711926</td>\n",
              "      <td>20669600.0</td>\n",
              "      <td>PETR4.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.231410</td>\n",
              "      <td>9.215684</td>\n",
              "      <td>8.410190</td>\n",
              "      <td>41.139328</td>\n",
              "      <td>-57.401203</td>\n",
              "      <td>11.167455</td>\n",
              "      <td>9.083429</td>\n",
              "      <td>9.781968</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>3.742000</td>\n",
              "      <td>3.816000</td>\n",
              "      <td>3.696000</td>\n",
              "      <td>3.460211</td>\n",
              "      <td>6829000.0</td>\n",
              "      <td>RADL3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.036516</td>\n",
              "      <td>3.787477</td>\n",
              "      <td>3.132766</td>\n",
              "      <td>53.818737</td>\n",
              "      <td>-48.439870</td>\n",
              "      <td>1.218313</td>\n",
              "      <td>3.536562</td>\n",
              "      <td>3.387031</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>9.292013</td>\n",
              "      <td>9.542526</td>\n",
              "      <td>9.185473</td>\n",
              "      <td>6.772543</td>\n",
              "      <td>3015150.0</td>\n",
              "      <td>RENT3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.019501</td>\n",
              "      <td>6.860302</td>\n",
              "      <td>6.015596</td>\n",
              "      <td>52.173430</td>\n",
              "      <td>76.266817</td>\n",
              "      <td>16.973351</td>\n",
              "      <td>6.585875</td>\n",
              "      <td>6.841913</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>37.250000</td>\n",
              "      <td>36.470001</td>\n",
              "      <td>20.544390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>VALE3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.565324</td>\n",
              "      <td>22.247736</td>\n",
              "      <td>19.670845</td>\n",
              "      <td>40.582172</td>\n",
              "      <td>-71.249572</td>\n",
              "      <td>26.254835</td>\n",
              "      <td>21.819530</td>\n",
              "      <td>22.507051</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>43.619999</td>\n",
              "      <td>20.678814</td>\n",
              "      <td>9900.0</td>\n",
              "      <td>VIVT3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.560063</td>\n",
              "      <td>23.568125</td>\n",
              "      <td>20.118588</td>\n",
              "      <td>41.313782</td>\n",
              "      <td>-135.274188</td>\n",
              "      <td>44.660532</td>\n",
              "      <td>22.197941</td>\n",
              "      <td>22.843590</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-05</td>\n",
              "      <td>2.973372</td>\n",
              "      <td>2.988165</td>\n",
              "      <td>2.934911</td>\n",
              "      <td>2.401510</td>\n",
              "      <td>2784444.0</td>\n",
              "      <td>WEGE3.SA</td>\n",
              "      <td>1</td>\n",
              "      <td>0.004863</td>\n",
              "      <td>2.497084</td>\n",
              "      <td>2.385461</td>\n",
              "      <td>49.398034</td>\n",
              "      <td>-80.988473</td>\n",
              "      <td>6.180105</td>\n",
              "      <td>2.437056</td>\n",
              "      <td>2.414865</td>\n",
              "      <td>[[0.00018903795517714915, 9.757488254570043e-0...</td>\n",
              "      <td>tic         ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e055ea77-96a4-4f81-aeee-a2483c890899')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e055ea77-96a4-4f81-aeee-a2483c890899 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e055ea77-96a4-4f81-aeee-a2483c890899');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxQTNjpblAMN"
      },
      "source": [
        "\n",
        "## Environment for Portfolio Allocation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlfE-VERbU40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
        "\n",
        "\n",
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A portfolio allocation environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then \n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "        \n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self, \n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct =transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.terminal = False     \n",
        "        self.turbulence_threshold = turbulence_threshold        \n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "        \n",
        "    def step(self, actions):\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            plt.plot(df.daily_return.cumsum(),'r')\n",
        "            plt.savefig('results/cumulative_reward.png')\n",
        "            plt.close()\n",
        "            \n",
        "            plt.plot(self.portfolio_return_memory,'r')\n",
        "            plt.savefig('results/rewards.png')\n",
        "            plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))           \n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() !=0:\n",
        "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                       df_daily_return['daily_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "            \n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            weights = self.softmax_normalization(actions) \n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day += 1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            log_portfolio_return = np.log(sum((self.data.close.values / last_day_memory.close.values)*weights))\n",
        "            # update portfolio value\n",
        "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])            \n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value\n",
        "            \n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.terminal = False \n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]] \n",
        "        return self.state\n",
        "    \n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "        \n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "    \n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "        \n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzD06X0CbU43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b300ea3-7834-4cda-c35d-431f1aab7caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 20, State Space: 20\n",
            "Feature Dimension: 4\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
        "tech_indicator_list = ['macd', 'rsi_30', 'cci_30', 'dx_30']\n",
        "feature_dimension = len(tech_indicator_list)\n",
        "print(f\"Feature Dimension: {feature_dimension}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiViKrd9sttr"
      },
      "outputs": [],
      "source": [
        "def extract_weights(drl_actions_list):\n",
        "    a2c_weight_df = {'date':[], 'weights':[]}\n",
        "    for i in range(len(drl_actions_list)):\n",
        "      date = drl_actions_list.index[i]\n",
        "      tic_list = list(drl_actions_list.columns)\n",
        "      weights_list = drl_actions_list.reset_index()[list(drl_actions_list.columns)].iloc[i].values\n",
        "      weight_dict = {'tic':[], 'weight':[]}\n",
        "      for j in range(len(tic_list)):\n",
        "        weight_dict['tic'] += [tic_list[j]]\n",
        "        weight_dict['weight'] += [weights_list[j]]\n",
        "\n",
        "      a2c_weight_df['date'] += [date]\n",
        "      a2c_weight_df['weights'] += [pd.DataFrame(weight_dict)]\n",
        "\n",
        "    a2c_weights = pd.DataFrame(a2c_weight_df)\n",
        "    return a2c_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCiDKcDXtrHg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "546d828f-faec-4a30-9668-6a9188e95ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
            "GO 26 iteration!!!!\n",
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4660158.105859533\n",
            "Sharpe:  0.7992371264646903\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 104       |\n",
            "|    time_elapsed    | 85        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -4.78e+07 |\n",
            "|    critic_loss     | 6.26e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 4910203.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 93        |\n",
            "|    time_elapsed    | 191       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.04e+08 |\n",
            "|    critic_loss     | 1.61e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 4910203.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 90        |\n",
            "|    time_elapsed    | 296       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.41e+08 |\n",
            "|    critic_loss     | 2.61e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 4910203.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 89        |\n",
            "|    time_elapsed    | 400       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.63e+08 |\n",
            "|    critic_loss     | 3.49e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 33420     |\n",
            "|    reward          | 4910203.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 87        |\n",
            "|    time_elapsed    | 508       |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.78e+08 |\n",
            "|    critic_loss     | 4.05e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 42332     |\n",
            "|    reward          | 4910203.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4910203.525940617\n",
            "Sharpe:  0.8165660934183507\n",
            "=================================\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5820146.540324267\n",
            "Sharpe:  0.9413234522728497\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091697.0760101285\n",
            "Sharpe:  0.9641361694885284\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091694.084614581\n",
            "Sharpe:  0.9641358983861412\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091682.937042997\n",
            "Sharpe:  0.9641351175164079\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 56        |\n",
            "|    time_elapsed    | 158       |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -7.42e+07 |\n",
            "|    critic_loss     | 1.02e+13  |\n",
            "|    ent_coef        | 1.6       |\n",
            "|    ent_coef_loss   | -83.8     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8811      |\n",
            "|    reward          | 6091683.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091696.26306558\n",
            "Sharpe:  0.9641357705491653\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091700.810277982\n",
            "Sharpe:  0.964135625701057\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091664.629796542\n",
            "Sharpe:  0.9641322336564615\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091574.6725906795\n",
            "Sharpe:  0.9641244700830619\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 56        |\n",
            "|    time_elapsed    | 317       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.32e+08 |\n",
            "|    critic_loss     | 1.2e+13   |\n",
            "|    ent_coef        | 21.5      |\n",
            "|    ent_coef_loss   | -422      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 17723     |\n",
            "|    reward          | 6091574.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091771.109623892\n",
            "Sharpe:  0.9641387279275323\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091500.4689714145\n",
            "Sharpe:  0.9641145518274837\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6091282.353068115\n",
            "Sharpe:  0.9640907827484946\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6089547.360382822\n",
            "Sharpe:  0.9639459622627455\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 55        |\n",
            "|    time_elapsed    | 478       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.69e+08 |\n",
            "|    critic_loss     | 2.19e+14  |\n",
            "|    ent_coef        | 278       |\n",
            "|    ent_coef_loss   | -516      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 26635     |\n",
            "|    reward          | 6089547.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6094071.355352308\n",
            "Sharpe:  0.9642678828621701\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6089919.120718677\n",
            "Sharpe:  0.9639105004260072\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6095931.35427485\n",
            "Sharpe:  0.9643422742990257\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6095167.593378101\n",
            "Sharpe:  0.9640968441867603\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 55        |\n",
            "|    time_elapsed    | 637       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.9e+08  |\n",
            "|    critic_loss     | 2.11e+13  |\n",
            "|    ent_coef        | 3.28e+03  |\n",
            "|    ent_coef_loss   | -365      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 35547     |\n",
            "|    reward          | 6095167.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6068449.668027976\n",
            "Sharpe:  0.9619616759433736\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6036463.79563918\n",
            "Sharpe:  0.9587548871264682\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6076180.610828035\n",
            "Sharpe:  0.9617112682762342\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6061796.938953192\n",
            "Sharpe:  0.9599194476607258\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 56        |\n",
            "|    time_elapsed    | 792       |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.82e+08 |\n",
            "|    critic_loss     | 2.52e+13  |\n",
            "|    ent_coef        | 2.46e+04  |\n",
            "|    ent_coef_loss   | -31.6     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 44459     |\n",
            "|    reward          | 6061797.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5924646.496996891\n",
            "Sharpe:  0.9476088584048247\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6069049.523639166\n",
            "Sharpe:  0.9589212466365802\n",
            "=================================\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5842328.268071496\n",
            "Sharpe:  0.9249839975623694\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 115       |\n",
            "|    time_elapsed    | 77        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.62e+07 |\n",
            "|    critic_loss     | 8.15e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 5600125.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 103       |\n",
            "|    time_elapsed    | 171       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.07e+07 |\n",
            "|    critic_loss     | 2.19e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 5600125.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 99        |\n",
            "|    time_elapsed    | 268       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -8.65e+07 |\n",
            "|    critic_loss     | 3.88e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 5600125.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5600125.457980571\n",
            "Sharpe:  0.9095254112843013\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:990122.0863136107\n",
            "Sharpe:  0.04814673106951116\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:954913.5319846483\n",
            "Sharpe:  -0.15712036458232206\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:928234.1178618898\n",
            "Sharpe:  -0.2869982958937982\n",
            "=================================\n",
            "hit end!\n",
            "GO 27 iteration!!!!\n",
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5968523.6118108295\n",
            "Sharpe:  0.9136806836675124\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 107       |\n",
            "|    time_elapsed    | 83        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -5.7e+07  |\n",
            "|    critic_loss     | 9.94e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 5601562.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 96        |\n",
            "|    time_elapsed    | 184       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.2e+08  |\n",
            "|    critic_loss     | 2.21e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 5601562.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 92        |\n",
            "|    time_elapsed    | 290       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.6e+08  |\n",
            "|    critic_loss     | 3.56e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 5601562.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 91        |\n",
            "|    time_elapsed    | 391       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.85e+08 |\n",
            "|    critic_loss     | 4.41e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 33420     |\n",
            "|    reward          | 5601562.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 89        |\n",
            "|    time_elapsed    | 496       |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2e+08    |\n",
            "|    critic_loss     | 5.36e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 42332     |\n",
            "|    reward          | 5601562.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5601562.281787696\n",
            "Sharpe:  0.8907297475957675\n",
            "=================================\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5691064.229170999\n",
            "Sharpe:  0.8908024085362556\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844952.988444116\n",
            "Sharpe:  0.9028173816117214\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844954.238762987\n",
            "Sharpe:  0.9028174647984747\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844994.968329035\n",
            "Sharpe:  0.9028206191776889\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 152       |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -7.31e+07 |\n",
            "|    critic_loss     | 1.1e+13   |\n",
            "|    ent_coef        | 1.6       |\n",
            "|    ent_coef_loss   | -84.1     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8811      |\n",
            "|    reward          | 5844995.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844978.6233748775\n",
            "Sharpe:  0.902819482893857\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844955.9030599315\n",
            "Sharpe:  0.9028180812284347\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844950.857207856\n",
            "Sharpe:  0.9028178964689985\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844966.643926055\n",
            "Sharpe:  0.9028195590861025\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 306       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.27e+08 |\n",
            "|    critic_loss     | 1.65e+13  |\n",
            "|    ent_coef        | 21.6      |\n",
            "|    ent_coef_loss   | -421      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 17723     |\n",
            "|    reward          | 5844966.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844824.732957553\n",
            "Sharpe:  0.9028115597312004\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844786.331958713\n",
            "Sharpe:  0.9028121562073897\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5845676.342490019\n",
            "Sharpe:  0.9028813778164215\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5845033.946991238\n",
            "Sharpe:  0.9028437173504256\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 460       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.66e+08 |\n",
            "|    critic_loss     | 1.99e+13  |\n",
            "|    ent_coef        | 278       |\n",
            "|    ent_coef_loss   | -519      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 26635     |\n",
            "|    reward          | 5845034.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5844913.7429299\n",
            "Sharpe:  0.902841802906345\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5842491.239814847\n",
            "Sharpe:  0.9026631526701798\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5845344.116020513\n",
            "Sharpe:  0.9029550321001539\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5849101.548509808\n",
            "Sharpe:  0.9032923121344476\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 57        |\n",
            "|    time_elapsed    | 614       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.85e+08 |\n",
            "|    critic_loss     | 2.48e+13  |\n",
            "|    ent_coef        | 3.27e+03  |\n",
            "|    ent_coef_loss   | -354      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 35547     |\n",
            "|    reward          | 5849101.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5827567.246862159\n",
            "Sharpe:  0.901941221835218\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5823982.083928997\n",
            "Sharpe:  0.9022370972066028\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5892530.190490421\n",
            "Sharpe:  0.9076397129590811\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5719852.988397007\n",
            "Sharpe:  0.8942683673072556\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 768       |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.8e+08  |\n",
            "|    critic_loss     | 3.22e+13  |\n",
            "|    ent_coef        | 2.42e+04  |\n",
            "|    ent_coef_loss   | -21.8     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 44459     |\n",
            "|    reward          | 5719853.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5951594.512543641\n",
            "Sharpe:  0.9129591056773425\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5909080.771467616\n",
            "Sharpe:  0.9091874657796454\n",
            "=================================\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4944052.870627628\n",
            "Sharpe:  0.8679241600355238\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 120       |\n",
            "|    time_elapsed    | 74        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.61e+07 |\n",
            "|    critic_loss     | 6.14e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 4982559.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 104       |\n",
            "|    time_elapsed    | 170       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.17e+07 |\n",
            "|    critic_loss     | 1.76e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 4982559.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 101       |\n",
            "|    time_elapsed    | 264       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -8.85e+07 |\n",
            "|    critic_loss     | 3.31e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 4982559.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4982559.326582725\n",
            "Sharpe:  0.8768318518189387\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:998620.5463716463\n",
            "Sharpe:  0.08657552410841644\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:966435.5190978289\n",
            "Sharpe:  -0.08404933415093523\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:944683.0898566864\n",
            "Sharpe:  -0.2031033672309233\n",
            "=================================\n",
            "hit end!\n",
            "GO 28 iteration!!!!\n",
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6194398.813858257\n",
            "Sharpe:  0.9413274754601851\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 111       |\n",
            "|    time_elapsed    | 80        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.02e+07 |\n",
            "|    critic_loss     | 1.17e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 6139071.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 96        |\n",
            "|    time_elapsed    | 184       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.28e+08 |\n",
            "|    critic_loss     | 2.64e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 6139071.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 93        |\n",
            "|    time_elapsed    | 285       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.71e+08 |\n",
            "|    critic_loss     | 4.05e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 6139071.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 85        |\n",
            "|    time_elapsed    | 416       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.97e+08 |\n",
            "|    critic_loss     | 5.36e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 33420     |\n",
            "|    reward          | 6139071.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 76        |\n",
            "|    time_elapsed    | 585       |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.14e+08 |\n",
            "|    critic_loss     | 6.47e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 42332     |\n",
            "|    reward          | 6139071.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6139070.9266992295\n",
            "Sharpe:  0.9414767028772364\n",
            "=================================\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5873776.514963086\n",
            "Sharpe:  0.9176548581267227\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881516.807726429\n",
            "Sharpe:  0.917988213841203\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881538.928017275\n",
            "Sharpe:  0.9179899259035269\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881532.077619307\n",
            "Sharpe:  0.9179893011823622\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 43        |\n",
            "|    time_elapsed    | 204       |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -7.24e+07 |\n",
            "|    critic_loss     | 1.44e+13  |\n",
            "|    ent_coef        | 1.59      |\n",
            "|    ent_coef_loss   | -82.5     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8811      |\n",
            "|    reward          | 5881532.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881542.024844538\n",
            "Sharpe:  0.9179901285882743\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881515.945690185\n",
            "Sharpe:  0.9179885410899884\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881460.805053882\n",
            "Sharpe:  0.9179838027267748\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881400.575937496\n",
            "Sharpe:  0.9179793607322546\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 41        |\n",
            "|    time_elapsed    | 429       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.27e+08 |\n",
            "|    critic_loss     | 1.62e+13  |\n",
            "|    ent_coef        | 21.5      |\n",
            "|    ent_coef_loss   | -417      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 17723     |\n",
            "|    reward          | 5881400.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881055.5325846495\n",
            "Sharpe:  0.9179537949688439\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881280.853600099\n",
            "Sharpe:  0.9179712447006727\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5881135.841825937\n",
            "Sharpe:  0.9179675292326028\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5880255.084561126\n",
            "Sharpe:  0.9179067146902464\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 41        |\n",
            "|    time_elapsed    | 650       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.64e+08 |\n",
            "|    critic_loss     | 1.9e+13   |\n",
            "|    ent_coef        | 277       |\n",
            "|    ent_coef_loss   | -511      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 26635     |\n",
            "|    reward          | 5880255.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5879763.580739565\n",
            "Sharpe:  0.9178526875267511\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5880734.40586916\n",
            "Sharpe:  0.9179369859544125\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5883953.437589308\n",
            "Sharpe:  0.9181854427102166\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5864802.4059971245\n",
            "Sharpe:  0.9167729300990501\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 40        |\n",
            "|    time_elapsed    | 874       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.83e+08 |\n",
            "|    critic_loss     | 1.98e+13  |\n",
            "|    ent_coef        | 3.26e+03  |\n",
            "|    ent_coef_loss   | -351      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 35547     |\n",
            "|    reward          | 5864802.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5879602.204435045\n",
            "Sharpe:  0.9179066467003539\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5887075.442515314\n",
            "Sharpe:  0.9186331074036702\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5926654.913496479\n",
            "Sharpe:  0.9214760233645244\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5804337.872337486\n",
            "Sharpe:  0.9120281469557565\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 40        |\n",
            "|    time_elapsed    | 1095      |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.77e+08 |\n",
            "|    critic_loss     | 2.7e+13   |\n",
            "|    ent_coef        | 2.43e+04  |\n",
            "|    ent_coef_loss   | -33.5     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 44459     |\n",
            "|    reward          | 5804338.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5950941.397799644\n",
            "Sharpe:  0.9233686503688529\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5932796.904004916\n",
            "Sharpe:  0.9222555099565338\n",
            "=================================\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5594522.830290672\n",
            "Sharpe:  0.8727994636253134\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 123       |\n",
            "|    time_elapsed    | 72        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.76e+07 |\n",
            "|    critic_loss     | 8.16e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 4909136.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 107       |\n",
            "|    time_elapsed    | 165       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.3e+07  |\n",
            "|    critic_loss     | 2.07e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 4909136.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 103       |\n",
            "|    time_elapsed    | 258       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -8.97e+07 |\n",
            "|    critic_loss     | 3.65e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 4909136.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4909136.49373932\n",
            "Sharpe:  0.8143096787190526\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:939658.0575445155\n",
            "Sharpe:  -0.22757038036567082\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:993823.833357522\n",
            "Sharpe:  0.056528622293817186\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:986770.1432262508\n",
            "Sharpe:  0.03441335784188718\n",
            "=================================\n",
            "hit end!\n",
            "GO 29 iteration!!!!\n",
            "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5182142.656409373\n",
            "Sharpe:  0.8596134413393199\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 107       |\n",
            "|    time_elapsed    | 82        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -4.91e+07 |\n",
            "|    critic_loss     | 7.02e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 4801252.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 97        |\n",
            "|    time_elapsed    | 183       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.05e+08 |\n",
            "|    critic_loss     | 1.61e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 4801252.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 93        |\n",
            "|    time_elapsed    | 284       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.4e+08  |\n",
            "|    critic_loss     | 2.51e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 4801252.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 91        |\n",
            "|    time_elapsed    | 388       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.62e+08 |\n",
            "|    critic_loss     | 3.27e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 33420     |\n",
            "|    reward          | 4801252.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 90        |\n",
            "|    time_elapsed    | 491       |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.76e+08 |\n",
            "|    critic_loss     | 3.98e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 42332     |\n",
            "|    reward          | 4801252.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4801251.961117121\n",
            "Sharpe:  0.8194744419016162\n",
            "=================================\n",
            "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5462842.107459675\n",
            "Sharpe:  0.8926774304451601\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286542.348481336\n",
            "Sharpe:  0.8777755997300437\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286526.884219881\n",
            "Sharpe:  0.8777743322662525\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286570.0640566815\n",
            "Sharpe:  0.8777780157837332\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 153       |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.86e+07 |\n",
            "|    critic_loss     | 7.68e+12  |\n",
            "|    ent_coef        | 1.6       |\n",
            "|    ent_coef_loss   | -82.6     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 8811      |\n",
            "|    reward          | 5286570.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286540.928996266\n",
            "Sharpe:  0.8777754500372238\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286595.2033856865\n",
            "Sharpe:  0.8777805152947288\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286578.063907434\n",
            "Sharpe:  0.877778141364286\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286716.046279417\n",
            "Sharpe:  0.8777900795693386\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 305       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.22e+08 |\n",
            "|    critic_loss     | 1.2e+13   |\n",
            "|    ent_coef        | 21.5      |\n",
            "|    ent_coef_loss   | -417      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 17723     |\n",
            "|    reward          | 5286716.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286457.783660201\n",
            "Sharpe:  0.8777692454150127\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286949.961392051\n",
            "Sharpe:  0.8778117192794264\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5287339.762500019\n",
            "Sharpe:  0.877841248705043\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286695.505838049\n",
            "Sharpe:  0.8777842193616359\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 57        |\n",
            "|    time_elapsed    | 461       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.55e+08 |\n",
            "|    critic_loss     | 1.44e+13  |\n",
            "|    ent_coef        | 277       |\n",
            "|    ent_coef_loss   | -503      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 26635     |\n",
            "|    reward          | 5286695.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5285918.446037741\n",
            "Sharpe:  0.8777144822776884\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5286083.24987146\n",
            "Sharpe:  0.8777274627508573\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5296186.105736389\n",
            "Sharpe:  0.8786107086992067\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5291810.7145424\n",
            "Sharpe:  0.8780339815269664\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 16        |\n",
            "|    fps             | 57        |\n",
            "|    time_elapsed    | 617       |\n",
            "|    total_timesteps | 35648     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.73e+08 |\n",
            "|    critic_loss     | 1.34e+13  |\n",
            "|    ent_coef        | 3.25e+03  |\n",
            "|    ent_coef_loss   | -348      |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 35547     |\n",
            "|    reward          | 5291810.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5296444.7172032315\n",
            "Sharpe:  0.8782766329013145\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5291825.922818731\n",
            "Sharpe:  0.8782399084494479\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5317243.960609665\n",
            "Sharpe:  0.8799438495130738\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5281816.166904357\n",
            "Sharpe:  0.8774088834123003\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 20        |\n",
            "|    fps             | 57        |\n",
            "|    time_elapsed    | 773       |\n",
            "|    total_timesteps | 44560     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -1.64e+08 |\n",
            "|    critic_loss     | 1.93e+13  |\n",
            "|    ent_coef        | 2.32e+04  |\n",
            "|    ent_coef_loss   | -22.6     |\n",
            "|    learning_rate   | 0.0003    |\n",
            "|    n_updates       | 44459     |\n",
            "|    reward          | 5281816.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5256559.281871771\n",
            "Sharpe:  0.8745232045233441\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5311475.785917833\n",
            "Sharpe:  0.8801717556463551\n",
            "=================================\n",
            "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
            "Using cuda device\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5250590.525139635\n",
            "Sharpe:  0.8606141465162854\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 119       |\n",
            "|    time_elapsed    | 74        |\n",
            "|    total_timesteps | 8912      |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -2.6e+07  |\n",
            "|    critic_loss     | 6.43e+12  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 6684      |\n",
            "|    reward          | 4965681.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 104       |\n",
            "|    time_elapsed    | 171       |\n",
            "|    total_timesteps | 17824     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -6.08e+07 |\n",
            "|    critic_loss     | 1.86e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 15596     |\n",
            "|    reward          | 4965681.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 12        |\n",
            "|    fps             | 101       |\n",
            "|    time_elapsed    | 263       |\n",
            "|    total_timesteps | 26736     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -8.71e+07 |\n",
            "|    critic_loss     | 3.37e+13  |\n",
            "|    learning_rate   | 0.001     |\n",
            "|    n_updates       | 24508     |\n",
            "|    reward          | 4965681.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4965680.77041717\n",
            "Sharpe:  0.8405147060841115\n",
            "=================================\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:980389.4186471832\n",
            "Sharpe:  -0.008150542075979936\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:988032.7604542157\n",
            "Sharpe:  0.023458537939248954\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:968058.0621825971\n",
            "Sharpe:  -0.07347251740466008\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "import pandas as pd\n",
        "from pypfopt import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pypfopt import objective_functions\n",
        "from pyfolio import timeseries\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 1000000, \n",
        "    \"transaction_cost_pct\": 0, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": tech_indicator_list, \n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-1    \n",
        "}\n",
        "\n",
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
        "\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))\n",
        "\n",
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "for i in range(0, 30):\n",
        "  print(f\"GO {i} iteration!!!!\")\n",
        "  agent = DRLAgent(env = env_train)\n",
        "  DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
        "  model_ddpg = agent.get_model(\"ddpg\",model_kwargs = DDPG_PARAMS)\n",
        "  trained_ddpg = agent.train_model(model=model_ddpg, \n",
        "                              tb_log_name='ddpg',\n",
        "                              total_timesteps=50000)\n",
        "  agent = DRLAgent(env = env_train)\n",
        "  SAC_PARAMS = {\n",
        "      \"batch_size\": 128,\n",
        "      \"buffer_size\": 100000,\n",
        "      \"learning_rate\": 0.0003,\n",
        "      \"learning_starts\": 100,\n",
        "      \"ent_coef\": \"auto_0.1\",\n",
        "  }\n",
        "\n",
        "  model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)\n",
        "  trained_sac = agent.train_model(model=model_sac, \n",
        "                              tb_log_name='sac',\n",
        "                              total_timesteps=50000)\n",
        "  \n",
        "  agent = DRLAgent(env = env_train)\n",
        "  TD3_PARAMS = {\"batch_size\": 100, \n",
        "                \"buffer_size\": 1000000, \n",
        "                \"learning_rate\": 0.001}\n",
        "  model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)\n",
        "  trained_td3 = agent.train_model(model=model_td3, \n",
        "                              tb_log_name='td3',\n",
        "                              total_timesteps=30000)\n",
        "  \n",
        "  trade = data_split(df,mid_date, end_date)\n",
        "  e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n",
        "\n",
        "  unique_tic = trade.tic.unique()\n",
        "  unique_trade_date = trade.date.unique()\n",
        "\n",
        "\n",
        "  df_daily_return_ddpg, df_actions_ddpg = DRLAgent.DRL_prediction(model=trained_ddpg,\n",
        "                          environment = e_trade_gym)\n",
        "  df_daily_return_sac, df_actions_sac = DRLAgent.DRL_prediction(model=trained_sac,\n",
        "                          environment = e_trade_gym)\n",
        "  df_daily_return_td3, df_actions_td3 = DRLAgent.DRL_prediction(model=trained_td3,\n",
        "                          environment = e_trade_gym)\n",
        "  time_ind = pd.Series(df_daily_return_ddpg.date)\n",
        "  ddpg_cumpod =(df_daily_return_ddpg.daily_return+1).cumprod()-1\n",
        "  sac_cumpod =(df_daily_return_sac.daily_return+1).cumprod()-1\n",
        "  td3_cumpod =(df_daily_return_td3.daily_return+1).cumprod()-1\n",
        "  DRL_strat_ddpg = convert_daily_return_to_pyfolio_ts(df_daily_return_ddpg)\n",
        "  DRL_strat_sac = convert_daily_return_to_pyfolio_ts(df_daily_return_sac)\n",
        "  DRL_strat_td3 = convert_daily_return_to_pyfolio_ts(df_daily_return_td3)\n",
        "\n",
        "  perf_func = timeseries.perf_stats \n",
        "  perf_stats_all_ddpg = perf_func( returns=DRL_strat_ddpg, \n",
        "                                factor_returns=DRL_strat_ddpg, \n",
        "                                  positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "  perf_stats_all_sac = perf_func( returns=DRL_strat_sac, \n",
        "                                factor_returns=DRL_strat_sac, \n",
        "                                  positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "  perf_stats_all_td3 = perf_func( returns=DRL_strat_td3, \n",
        "                                factor_returns=DRL_strat_td3, \n",
        "                                  positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "\n",
        "  ddpg_weights = extract_weights(df_actions_ddpg)\n",
        "  sac_weights = extract_weights(df_actions_sac)\n",
        "  td3_weights = extract_weights(df_actions_td3)\n",
        "\n",
        "  perf_stats_all_ddpg.to_csv(\"./perf_stats_all_ddpg_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '15sm4TEM7G8VVItnaPQuD4HB3lp6wHQV8'}]})\n",
        "  f.SetContentFile(\"./perf_stats_all_ddpg_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_actions_ddpg.to_csv(\"./df_actions_ddpg_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1tA93U2XD7nMatHYElv_7SP89iufIlnu5'}]})\n",
        "  f.SetContentFile(\"./df_actions_ddpg_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_daily_return_ddpg.to_csv(\"./df_daily_return_ddpg_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1UF1I-IL5ZG3xzBz9p3Z1CIucg46EPI4r'}]})\n",
        "  f.SetContentFile(\"./df_daily_return_ddpg_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  perf_stats_all_sac.to_csv(\"./perf_stats_all_sac_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1XyaCgPFOqb3_epJ4hZixwGS0hdT_6t_7'}]})\n",
        "  f.SetContentFile(\"./perf_stats_all_sac_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_actions_sac.to_csv(\"./df_actions_sac_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1Oj9f_V2Ut7sMi83keUf4VYbEYlvt_Vb-'}]})\n",
        "  f.SetContentFile(\"./df_actions_sac_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_daily_return_sac.to_csv(\"./df_daily_return_sac_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1f5bx2XmoNFtdpvY4inBZ4Vhj1kEqurAB'}]})\n",
        "  f.SetContentFile(\"./df_daily_return_sac_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  perf_stats_all_td3.to_csv(\"./perf_stats_all_td3_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1NshfoOh8iYljhHSSlaZYRWQmbGLP2LBA'}]})\n",
        "  f.SetContentFile(\"./perf_stats_all_td3_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_actions_td3.to_csv(\"./df_actions_td3_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '14xkfcLEWVjpIM_Ih_KKnGV9-lVmuWjRV'}]})\n",
        "  f.SetContentFile(\"./df_actions_td3_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_daily_return_td3.to_csv(\"./df_daily_return_td3_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1CmSokyimTYPfnkwCPYSxo-6PT7bJ5pIa'}]})\n",
        "  f.SetContentFile(\"./df_daily_return_td3_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyg0_ZuVEVQ5",
        "outputId": "f092af90-e497-411c-d169-4ad3c6099939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "|    fps                | 372       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 3.86e+08  |\n",
            "|    reward             | 2714098.0 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 2.46e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5977061.158875976\n",
            "Sharpe:  0.924434451289458\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 372       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 1.96e+08  |\n",
            "|    reward             | 1326196.4 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 6.15e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 373       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 3.46e+08  |\n",
            "|    reward             | 2226109.0 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 1.98e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5713476.4233606355\n",
            "Sharpe:  0.899011852447141\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 372       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 1.79e+08  |\n",
            "|    reward             | 1203847.4 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 4.96e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 373       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 2.56e+08  |\n",
            "|    reward             | 1625941.5 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 1.03e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 7.02e+08  |\n",
            "|    reward             | 4828936.5 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 7.51e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5193511.806236433\n",
            "Sharpe:  0.8607771673436755\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 373       |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | 1.68e+08  |\n",
            "|    reward             | 993233.2  |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 4.33e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 112       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 5.92e+08  |\n",
            "|    reward             | 4354117.5 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 6.58e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5447316.70581148\n",
            "Sharpe:  0.8841208016640569\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 114       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 1.74e+08  |\n",
            "|    reward             | 1183803.1 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 4.72e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 117       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 4.34e+08  |\n",
            "|    reward             | 2903405.5 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 2.98e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4922964.725402362\n",
            "Sharpe:  0.8410029686939627\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 1.81e+08  |\n",
            "|    reward             | 1125136.9 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 4.65e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 3.67e+08  |\n",
            "|    reward             | 2590279.5 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 2.45e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4929011.977354293\n",
            "Sharpe:  0.83896748489738\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 125       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 1.75e+08  |\n",
            "|    reward             | 1217152.9 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 5.59e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 2.61e+08  |\n",
            "|    reward             | 1913903.9 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 1.22e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 130       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 8e+08     |\n",
            "|    reward             | 5282638.5 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 9.66e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5564865.20537993\n",
            "Sharpe:  0.8912625445117331\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 133       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 2.16e+08  |\n",
            "|    reward             | 1272253.5 |\n",
            "|    std                | 0.97      |\n",
            "|    value_loss         | 6.4e+13   |\n",
            "-------------------------------------\n",
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.001, 'batch_size': 128}\n",
            "Using cuda device\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 483       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 4         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 4200566.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5575408.142203676\n",
            "Sharpe:  0.886949930821702\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.022187e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.66e+14     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -4.46e-06    |\n",
            "|    reward               | 3970296.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.34e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5356766.49603036\n",
            "Sharpe:  0.8727735433176667\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 413          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.807991e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.96e+14     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -4.98e-06    |\n",
            "|    reward               | 2856967.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.45e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5153068.851279152\n",
            "Sharpe:  0.8573250201577037\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 408         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 20          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.58563e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 6.52e+14    |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -3.75e-06   |\n",
            "|    reward               | 2007747.0   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.47e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4479873.569377808\n",
            "Sharpe:  0.795553600983883\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 405          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.546056e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.39e+14     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -4.54e-06    |\n",
            "|    reward               | 2600667.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.51e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6053802.341071178\n",
            "Sharpe:  0.9276057606920428\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 31           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.400537e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.87e+14     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -4.12e-06    |\n",
            "|    reward               | 2050277.9    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.44e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6007592.888996145\n",
            "Sharpe:  0.9144021054850474\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 379          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.760253e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 2.38e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.09e+15     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -3.91e-06    |\n",
            "|    reward               | 1559903.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.34e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5506938.448117014\n",
            "Sharpe:  0.8854014626572487\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 380          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 43           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.411007e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.15e+15     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -3.83e-06    |\n",
            "|    reward               | 1182788.9    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.24e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5259568.727039476\n",
            "Sharpe:  0.8717495092220695\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 381          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 48           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.392373e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.07e+15     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -3.31e-06    |\n",
            "|    reward               | 1205086.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.13e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4988060.5642679045\n",
            "Sharpe:  0.8417792906807757\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 382           |\n",
            "|    iterations           | 10            |\n",
            "|    time_elapsed         | 53            |\n",
            "|    total_timesteps      | 20480         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 8.3236955e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 8.93e+14      |\n",
            "|    n_updates            | 90            |\n",
            "|    policy_gradient_loss | -3.72e-06     |\n",
            "|    reward               | 1052983.1     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.82e+15      |\n",
            "-------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4674500.183240899\n",
            "Sharpe:  0.8159121581129625\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 383          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.294592e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.93e+14     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -3.46e-06    |\n",
            "|    reward               | 1188588.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.71e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5096161.1520353705\n",
            "Sharpe:  0.8513535398473947\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 383           |\n",
            "|    iterations           | 12            |\n",
            "|    time_elapsed         | 64            |\n",
            "|    total_timesteps      | 24576         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 9.6915755e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 7.1e+14       |\n",
            "|    n_updates            | 110           |\n",
            "|    policy_gradient_loss | -4.86e-06     |\n",
            "|    reward               | 1171766.2     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.38e+15      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 384          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 69           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.731149e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.42e+14     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -3.91e-06    |\n",
            "|    reward               | 4801343.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.8e+15      |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5432695.24266586\n",
            "Sharpe:  0.8797989462335455\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 385           |\n",
            "|    iterations           | 14            |\n",
            "|    time_elapsed         | 74            |\n",
            "|    total_timesteps      | 28672         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 7.9744495e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 8.02e+14      |\n",
            "|    n_updates            | 130           |\n",
            "|    policy_gradient_loss | -4.13e-06     |\n",
            "|    reward               | 3226506.2     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.69e+15      |\n",
            "-------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5522427.473277534\n",
            "Sharpe:  0.8904566811851167\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.236384e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.77e+14     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -4.21e-06    |\n",
            "|    reward               | 4181112.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.65e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6134603.708583622\n",
            "Sharpe:  0.9307480523903755\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.643838e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.83e+14     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -4.65e-06    |\n",
            "|    reward               | 2794386.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.76e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6508118.250124683\n",
            "Sharpe:  0.957380014149963\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.381903e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.17e+15     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -3.75e-06    |\n",
            "|    reward               | 2205184.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.04e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4707733.365554621\n",
            "Sharpe:  0.8124586709338293\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.138603e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.2e+15      |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -3.6e-06     |\n",
            "|    reward               | 1567169.1    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.28e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4400876.380330911\n",
            "Sharpe:  0.7848410450963532\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 386          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.080395e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.85e+14     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -4.04e-06    |\n",
            "|    reward               | 1473663.4    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.47e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4663669.356155773\n",
            "Sharpe:  0.8099647406052911\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 386         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 9.34233e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 5.57e+14    |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -4.29e-06   |\n",
            "|    reward               | 1225316.1   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.28e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:979350.3402023141\n",
            "Sharpe:  -0.016446161600363253\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:987479.1242996559\n",
            "Sharpe:  0.026626330301738995\n",
            "=================================\n",
            "hit end!\n",
            "GO 27 iteration!!!!\n",
            "{'n_steps': 10, 'ent_coef': 0.005, 'learning_rate': 0.0004}\n",
            "Using cuda device\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 2e+08     |\n",
            "|    reward             | 1273169.2 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 6.09e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 392       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 5.36e+08  |\n",
            "|    reward             | 3443001.8 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 4.16e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4704028.84950338\n",
            "Sharpe:  0.8178287628352898\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 2.07e+08  |\n",
            "|    reward             | 1358420.6 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 7.26e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 389       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 5.84e+08  |\n",
            "|    reward             | 3829658.2 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 5.36e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5929737.613775445\n",
            "Sharpe:  0.9205002306402748\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 1.89e+08  |\n",
            "|    reward             | 1329706.2 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 5.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 388       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 4.57e+08  |\n",
            "|    reward             | 2825199.8 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 3.22e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6178723.163985593\n",
            "Sharpe:  0.9347400062055018\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.69e+08  |\n",
            "|    reward             | 1229227.6 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 4.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 2.8e+08   |\n",
            "|    reward             | 1965257.4 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 1.35e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4691852.943620388\n",
            "Sharpe:  0.8185551501226129\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 1.7e+08   |\n",
            "|    reward             | 1133139.2 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 4.88e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 2.24e+08  |\n",
            "|    reward             | 1678165.0 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 9.03e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 4.87e+08  |\n",
            "|    reward             | 3317708.0 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 3.98e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4326000.505279413\n",
            "Sharpe:  0.7801293374628383\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 1.98e+08  |\n",
            "|    reward             | 1233822.4 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 5.8e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 5.9e+08   |\n",
            "|    reward             | 4080274.0 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 5.66e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5423338.752826216\n",
            "Sharpe:  0.8776929652864836\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 1.63e+08  |\n",
            "|    reward             | 1092726.4 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 4.95e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 3.87e+08  |\n",
            "|    reward             | 2690683.8 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 2.37e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4827965.863937817\n",
            "Sharpe:  0.8267673822465789\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 41        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 1.68e+08  |\n",
            "|    reward             | 1087765.0 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 4.71e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 3.32e+08  |\n",
            "|    reward             | 2253627.8 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 1.6e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4498018.649569318\n",
            "Sharpe:  0.7972781858780574\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 1.79e+08  |\n",
            "|    reward             | 1251493.6 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 5.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 2.91e+08  |\n",
            "|    reward             | 1863999.6 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 1.37e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 6.89e+08  |\n",
            "|    reward             | 4557028.0 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 6.87e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5052164.978107177\n",
            "Sharpe:  0.848957528688231\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 2.13e+08  |\n",
            "|    reward             | 1350599.8 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 6.2e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 4.32e+08  |\n",
            "|    reward             | 3126131.8 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 2.9e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5172097.743882099\n",
            "Sharpe:  0.8558410497041071\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 59        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 1.93e+08  |\n",
            "|    reward             | 1299262.0 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 5.63e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 4.68e+08  |\n",
            "|    reward             | 3003711.5 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 3.37e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4725193.159629189\n",
            "Sharpe:  0.8168919257106043\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 1.77e+08  |\n",
            "|    reward             | 1159826.4 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 5.24e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 3.33e+08  |\n",
            "|    reward             | 1989998.1 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 1.93e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4728246.774676115\n",
            "Sharpe:  0.8178235755903622\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 381       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 1.69e+08  |\n",
            "|    reward             | 1093331.9 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 5.04e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 2.36e+08  |\n",
            "|    reward             | 1764431.9 |\n",
            "|    std                | 0.97      |\n",
            "|    value_loss         | 9.8e+13   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4922330.5626624655\n",
            "Sharpe:  0.8375314594345274\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 1.55e+08  |\n",
            "|    reward             | 1082601.5 |\n",
            "|    std                | 0.968     |\n",
            "|    value_loss         | 3.87e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 79        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 2.09e+08  |\n",
            "|    reward             | 1514398.1 |\n",
            "|    std                | 0.968     |\n",
            "|    value_loss         | 7.06e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 376       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 6.17e+08  |\n",
            "|    reward             | 4094441.5 |\n",
            "|    std                | 0.968     |\n",
            "|    value_loss         | 6.28e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5173388.333881746\n",
            "Sharpe:  0.8613699519895789\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 375        |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 85         |\n",
            "|    total_timesteps    | 32000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -27.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0004     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | 1.59e+08   |\n",
            "|    reward             | 1018982.56 |\n",
            "|    std                | 0.966      |\n",
            "|    value_loss         | 3.64e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 376       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 87        |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 4.79e+08  |\n",
            "|    reward             | 3402349.5 |\n",
            "|    std                | 0.966     |\n",
            "|    value_loss         | 3.68e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4732336.253996005\n",
            "Sharpe:  0.8203717370316123\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 376       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 1.67e+08  |\n",
            "|    reward             | 1131453.4 |\n",
            "|    std                | 0.966     |\n",
            "|    value_loss         | 4.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 376       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 92        |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 2.83e+08  |\n",
            "|    reward             | 1994140.5 |\n",
            "|    std                | 0.965     |\n",
            "|    value_loss         | 1.31e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4170489.4025042816\n",
            "Sharpe:  0.7608077731279408\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 376       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 95        |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1231575.4 |\n",
            "|    std                | 0.965     |\n",
            "|    value_loss         | 5.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 376       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 98        |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 2.94e+08  |\n",
            "|    reward             | 1975544.2 |\n",
            "|    std                | 0.964     |\n",
            "|    value_loss         | 1.57e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5028051.851177509\n",
            "Sharpe:  0.8466656267676032\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 376       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 100       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 1.59e+08  |\n",
            "|    reward             | 1172054.2 |\n",
            "|    std                | 0.964     |\n",
            "|    value_loss         | 4.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 377       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 2.26e+08  |\n",
            "|    reward             | 1423757.4 |\n",
            "|    std                | 0.963     |\n",
            "|    value_loss         | 7.99e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 377       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 105       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 6.28e+08  |\n",
            "|    reward             | 4349119.0 |\n",
            "|    std                | 0.963     |\n",
            "|    value_loss         | 6.16e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4748444.986406695\n",
            "Sharpe:  0.8169494647139\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 377       |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 108       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | 1.44e+08  |\n",
            "|    reward             | 893566.94 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 3.5e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 111       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 6.28e+08  |\n",
            "|    reward             | 4188454.0 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 6.2e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5083625.937869146\n",
            "Sharpe:  0.8505345252742055\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 1.64e+08  |\n",
            "|    reward             | 1029532.8 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 3.69e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 116       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 4.12e+08  |\n",
            "|    reward             | 2871207.8 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 2.88e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4966380.410337728\n",
            "Sharpe:  0.8364783022449461\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 119       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 1.59e+08  |\n",
            "|    reward             | 1019517.3 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 3.85e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 121       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 3.26e+08  |\n",
            "|    reward             | 2380403.2 |\n",
            "|    std                | 0.961     |\n",
            "|    value_loss         | 2.08e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5492127.230104332\n",
            "Sharpe:  0.882355415645428\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 124       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 1.82e+08  |\n",
            "|    reward             | 1209499.1 |\n",
            "|    std                | 0.962     |\n",
            "|    value_loss         | 5.53e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 126       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 2.54e+08  |\n",
            "|    reward             | 1739407.5 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 1.02e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 129       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 5.94e+08  |\n",
            "|    reward             | 4235945.0 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 6.26e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4452453.020325938\n",
            "Sharpe:  0.788026526069922\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 378       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 132       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 1.79e+08  |\n",
            "|    reward             | 1222776.9 |\n",
            "|    std                | 0.96      |\n",
            "|    value_loss         | 5.83e+13  |\n",
            "-------------------------------------\n",
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.001, 'batch_size': 128}\n",
            "Using cuda device\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 479       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 4         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 4132660.2 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5359286.795255589\n",
            "Sharpe:  0.8728298685531568\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 431           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 9             |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.0069925e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 7.8e+14       |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -4.82e-06     |\n",
            "|    reward               | 4513504.0     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.33e+15      |\n",
            "-------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5643877.788217086\n",
            "Sharpe:  0.9001775388127743\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 418          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.479684e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.25e+14     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -3.81e-06    |\n",
            "|    reward               | 2818040.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.59e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5211896.837733973\n",
            "Sharpe:  0.8561738281681182\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 411          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.556526e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.75e+14     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -3.64e-06    |\n",
            "|    reward               | 2217495.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.58e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5112569.569331947\n",
            "Sharpe:  0.8489701122141132\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 405         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.20728e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 1.79e-07    |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 7.47e+14    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -4.18e-06   |\n",
            "|    reward               | 2393912.5   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.56e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5438452.80792969\n",
            "Sharpe:  0.8750683867270479\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 403          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.022187e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.76e+14     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -3.84e-06    |\n",
            "|    reward               | 1827573.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.73e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4565313.93582358\n",
            "Sharpe:  0.7987544100706191\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 402          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 35           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.712515e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.55e+14     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -3.44e-06    |\n",
            "|    reward               | 1454042.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.88e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6813075.544810999\n",
            "Sharpe:  0.9745469163347859\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 401          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.760253e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.33e+14     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -4.6e-06     |\n",
            "|    reward               | 1243784.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.56e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6310286.318006194\n",
            "Sharpe:  0.9487955219417156\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 400          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.003553e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.25e+15     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -3.32e-06    |\n",
            "|    reward               | 1218326.9    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.5e+15      |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5139683.655124108\n",
            "Sharpe:  0.8568277327782619\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 399          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 51           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.381903e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.14e+15     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -2.99e-06    |\n",
            "|    reward               | 1105326.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.34e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5490217.736458967\n",
            "Sharpe:  0.8830277194979508\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 398          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.789357e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.04e+15     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -4.27e-06    |\n",
            "|    reward               | 1239527.1    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.8e+15      |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4608742.710835693\n",
            "Sharpe:  0.8058484325696591\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 397          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 61           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.450581e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.1e+14      |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -4.44e-06    |\n",
            "|    reward               | 1178991.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.86e+15     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 397          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 66           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.887138e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.82e+14     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -3.91e-06    |\n",
            "|    reward               | 4743496.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.53e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5413702.827272323\n",
            "Sharpe:  0.8791679757462172\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 397          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 72           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.284122e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.92e+14     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -4.71e-06    |\n",
            "|    reward               | 3198375.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.56e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5306596.363427515\n",
            "Sharpe:  0.8719660077676404\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 396          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 77           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.119969e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.61e+14     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -3.77e-06    |\n",
            "|    reward               | 3218006.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.56e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5106898.891158976\n",
            "Sharpe:  0.8550415666025705\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 396         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 82          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 9.57516e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 7.29e+14    |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -4.69e-06   |\n",
            "|    reward               | 3194772.2   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.37e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6794247.135074419\n",
            "Sharpe:  0.9797463702249376\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 396          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 87           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.683411e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.34e+14     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -3.88e-06    |\n",
            "|    reward               | 2558912.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.66e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5493160.431163928\n",
            "Sharpe:  0.882479512956283\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 396          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 93           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.712515e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.45e+15     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -3.83e-06    |\n",
            "|    reward               | 1952477.4    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.48e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5009077.498294813\n",
            "Sharpe:  0.844354059732936\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 392          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 99           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.236384e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.08e+14     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -3.59e-06    |\n",
            "|    reward               | 1736627.1    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.9e+15      |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5224425.292157521\n",
            "Sharpe:  0.8631192196411395\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 105          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.167707e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.2e+14      |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -4.05e-06    |\n",
            "|    reward               | 1168669.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.73e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:999274.0224802742\n",
            "Sharpe:  0.09106876200059554\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:987385.9687074497\n",
            "Sharpe:  0.026118053190901092\n",
            "=================================\n",
            "hit end!\n",
            "GO 28 iteration!!!!\n",
            "{'n_steps': 10, 'ent_coef': 0.005, 'learning_rate': 0.0004}\n",
            "Using cuda device\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 396       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 2.06e+08  |\n",
            "|    reward             | 1316790.8 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 6.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 398       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 6.02e+08  |\n",
            "|    reward             | 3919787.2 |\n",
            "|    std                | 0.998     |\n",
            "|    value_loss         | 5.27e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5285848.017152108\n",
            "Sharpe:  0.8674771298859046\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 1.92e+08  |\n",
            "|    reward             | 1205772.8 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 5.68e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 390       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 6.39e+08  |\n",
            "|    reward             | 3929299.8 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 5.59e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5820710.495317638\n",
            "Sharpe:  0.9063277479854033\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 1.96e+08  |\n",
            "|    reward             | 1282034.8 |\n",
            "|    std                | 0.996     |\n",
            "|    value_loss         | 5.47e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 388       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 3.42e+08  |\n",
            "|    reward             | 2195809.5 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 1.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5180237.900851776\n",
            "Sharpe:  0.8617079027699436\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.88e+08  |\n",
            "|    reward             | 1268575.9 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 5.12e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 388       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 3.29e+08  |\n",
            "|    reward             | 2210633.0 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 1.75e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5242422.319357165\n",
            "Sharpe:  0.8650092109184531\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 1.89e+08  |\n",
            "|    reward             | 1157581.6 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 5.13e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 2.77e+08  |\n",
            "|    reward             | 1993248.0 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 1.29e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 388       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 7.01e+08  |\n",
            "|    reward             | 4369331.5 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 6.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5830775.71901222\n",
            "Sharpe:  0.9048492768063339\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 1.78e+08  |\n",
            "|    reward             | 1226237.0 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 5.63e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 6.44e+08  |\n",
            "|    reward             | 4224207.0 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 6.03e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5563017.548552969\n",
            "Sharpe:  0.891574413440919\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1221669.5 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 6.08e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 4.79e+08  |\n",
            "|    reward             | 3103494.2 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 3.13e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5949164.896441156\n",
            "Sharpe:  0.9182049663875247\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 41        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 1.81e+08  |\n",
            "|    reward             | 1161551.2 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 5.41e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 3.62e+08  |\n",
            "|    reward             | 2538871.2 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 2.02e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5076556.94773883\n",
            "Sharpe:  0.847930158950763\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 1.83e+08  |\n",
            "|    reward             | 1240620.9 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 5.73e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 49        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 2.77e+08  |\n",
            "|    reward             | 1703107.8 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 1.11e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 6.47e+08  |\n",
            "|    reward             | 4473961.5 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 6.56e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4932791.807062151\n",
            "Sharpe:  0.8371523211596648\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 2.18e+08  |\n",
            "|    reward             | 1372856.8 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 6.48e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 4.84e+08  |\n",
            "|    reward             | 3652959.8 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 3.79e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5857541.026751816\n",
            "Sharpe:  0.914930284735809\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 59        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 1.91e+08  |\n",
            "|    reward             | 1400848.8 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 6.23e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 4.5e+08   |\n",
            "|    reward             | 3086285.2 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 3.58e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5100341.06893132\n",
            "Sharpe:  0.8485510779298217\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 1.81e+08  |\n",
            "|    reward             | 1170409.8 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 5.34e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 3.53e+08  |\n",
            "|    reward             | 2028617.1 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 1.94e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4356276.2456822395\n",
            "Sharpe:  0.7758429925902374\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 1.88e+08  |\n",
            "|    reward             | 1121060.6 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 5.27e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 2.51e+08  |\n",
            "|    reward             | 1896103.4 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 1.13e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5643162.1908383975\n",
            "Sharpe:  0.8885239894925564\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 1.58e+08  |\n",
            "|    reward             | 1084881.9 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 3.84e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 78        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 2.23e+08  |\n",
            "|    reward             | 1587848.4 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 8.03e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 5.87e+08  |\n",
            "|    reward             | 3976697.8 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 5.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4959634.212905927\n",
            "Sharpe:  0.8312755458524022\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 83        |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 1.89e+08  |\n",
            "|    reward             | 1234396.5 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 5.31e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 5.07e+08  |\n",
            "|    reward             | 3779767.5 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 4.6e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5793692.167003203\n",
            "Sharpe:  0.899194096388089\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1277947.1 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 5.95e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 3.69e+08  |\n",
            "|    reward             | 2650545.2 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 2.28e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5428630.416977832\n",
            "Sharpe:  0.8722631856972864\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 1.93e+08  |\n",
            "|    reward             | 1357944.9 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 6.54e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 3.25e+08  |\n",
            "|    reward             | 2198077.2 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 1.96e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5211585.00142064\n",
            "Sharpe:  0.8566096137776447\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 99        |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 1.8e+08   |\n",
            "|    reward             | 1189601.2 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 4.78e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 2.6e+08   |\n",
            "|    reward             | 1691446.5 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 1.11e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 7.31e+08  |\n",
            "|    reward             | 5292152.5 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 9.07e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5741465.837059263\n",
            "Sharpe:  0.8976754988149218\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 384      |\n",
            "|    iterations         | 4100     |\n",
            "|    time_elapsed       | 106      |\n",
            "|    total_timesteps    | 41000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -27.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0004   |\n",
            "|    n_updates          | 4099     |\n",
            "|    policy_loss        | 1.51e+08 |\n",
            "|    reward             | 921860.9 |\n",
            "|    std                | 0.977    |\n",
            "|    value_loss         | 3.81e+13 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 6.63e+08  |\n",
            "|    reward             | 4401908.0 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 6.8e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5279304.922931823\n",
            "Sharpe:  0.8582390351054469\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 111       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 1.72e+08  |\n",
            "|    reward             | 1195214.4 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 4.67e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 114       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 4.16e+08  |\n",
            "|    reward             | 2978452.5 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 3.11e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4644473.322581413\n",
            "Sharpe:  0.8052808100304891\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 117       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 1.55e+08  |\n",
            "|    reward             | 1080377.6 |\n",
            "|    std                | 0.978     |\n",
            "|    value_loss         | 4.19e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 119       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 3.75e+08  |\n",
            "|    reward             | 2507547.5 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 2.28e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5335099.556061286\n",
            "Sharpe:  0.8656720776971375\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 1.85e+08  |\n",
            "|    reward             | 1221536.1 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 5.68e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 125       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 3.07e+08  |\n",
            "|    reward             | 2103863.5 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 1.5e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 7.82e+08  |\n",
            "|    reward             | 5513276.5 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 1.07e+15  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5774157.285941898\n",
            "Sharpe:  0.9016470868110273\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 383       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 130       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 2.26e+08  |\n",
            "|    reward             | 1440434.6 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 8.27e+13  |\n",
            "-------------------------------------\n",
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.001, 'batch_size': 128}\n",
            "Using cuda device\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 435       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 4         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 4078874.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5221664.406516826\n",
            "Sharpe:  0.8633912908586103\n",
            "=================================\n",
            "--------------------------------------------\n",
            "| time/                   |                |\n",
            "|    fps                  | 360            |\n",
            "|    iterations           | 2              |\n",
            "|    time_elapsed         | 11             |\n",
            "|    total_timesteps      | 4096           |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 1.03900675e-08 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -28.4          |\n",
            "|    explained_variance   | 0              |\n",
            "|    learning_rate        | 0.001          |\n",
            "|    loss                 | 5.97e+14       |\n",
            "|    n_updates            | 10             |\n",
            "|    policy_gradient_loss | -5.32e-06      |\n",
            "|    reward               | 4215604.5      |\n",
            "|    std                  | 1              |\n",
            "|    value_loss           | 1.22e+15       |\n",
            "--------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5632728.16514626\n",
            "Sharpe:  0.8947157828707271\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 370          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.225914e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.52e+14     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -4.12e-06    |\n",
            "|    reward               | 3056612.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.47e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5653195.961711403\n",
            "Sharpe:  0.9017425200540288\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 374          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.643838e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.26e+14     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -4.74e-06    |\n",
            "|    reward               | 2309330.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.63e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5984877.717962071\n",
            "Sharpe:  0.9233828651390393\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 27           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.294592e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.26e+14     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -4e-06       |\n",
            "|    reward               | 2174418.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.79e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5041026.763678983\n",
            "Sharpe:  0.8411323113116174\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 380          |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.712515e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.85e+14     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -3.53e-06    |\n",
            "|    reward               | 1853564.4    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.98e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4716454.059665801\n",
            "Sharpe:  0.8166139281296196\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 381          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 37           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.916242e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.78e+14     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -4.4e-06     |\n",
            "|    reward               | 1416378.4    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.63e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5333261.768051705\n",
            "Sharpe:  0.8665715843823008\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 383          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.760253e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.71e+14     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -3.97e-06    |\n",
            "|    reward               | 1097335.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.58e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4999276.49821293\n",
            "Sharpe:  0.8383220181407959\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 384          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 47           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.741619e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.08e+15     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -3.92e-06    |\n",
            "|    reward               | 1233917.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.96e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5576193.119722823\n",
            "Sharpe:  0.8878401623461688\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 384          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 53           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.770723e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.87e+14     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -3.68e-06    |\n",
            "|    reward               | 1210383.6    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.71e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5354593.208550131\n",
            "Sharpe:  0.8727329325983221\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.876668e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.49e+14     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -3.73e-06    |\n",
            "|    reward               | 1204339.6    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.04e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5969318.926840922\n",
            "Sharpe:  0.9199743856626187\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.566996e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.1e+15      |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -3.3e-06     |\n",
            "|    reward               | 1149033.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.96e+15     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 386          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 68           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.352799e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.09e+15     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -3.92e-06    |\n",
            "|    reward               | 4299296.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.21e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4872898.661441271\n",
            "Sharpe:  0.8316670948260031\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 386          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.749783e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.17e+14     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -4.37e-06    |\n",
            "|    reward               | 2990716.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.28e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5220076.220043552\n",
            "Sharpe:  0.8620116133939667\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 386          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.138603e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.74e+14     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -4.24e-06    |\n",
            "|    reward               | 3428230.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.37e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5491986.405373999\n",
            "Sharpe:  0.884015752085751\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 386          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.945346e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.65e+14     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -4.2e-06     |\n",
            "|    reward               | 2299439.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.39e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5020538.320881289\n",
            "Sharpe:  0.8451440485968413\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 387          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.265488e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.82e+14     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -4.03e-06    |\n",
            "|    reward               | 2560030.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.56e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5515548.921866048\n",
            "Sharpe:  0.8860268962628751\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 387          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.178176e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.85e+14     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -4.26e-06    |\n",
            "|    reward               | 2069696.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.52e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5425244.219354139\n",
            "Sharpe:  0.8795755921501108\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 387          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 100          |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.411007e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.51e+14     |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -3.97e-06    |\n",
            "|    reward               | 1714371.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.95e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5374356.363947854\n",
            "Sharpe:  0.8769671918473595\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 105          |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.760253e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.15e+15     |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -3.72e-06    |\n",
            "|    reward               | 1080283.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.05e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:997926.5531534376\n",
            "Sharpe:  0.08190081779592051\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:987440.0595379325\n",
            "Sharpe:  0.02640325298871407\n",
            "=================================\n",
            "hit end!\n",
            "GO 29 iteration!!!!\n",
            "{'n_steps': 10, 'ent_coef': 0.005, 'learning_rate': 0.0004}\n",
            "Using cuda device\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 393       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 2         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1287504.6 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 6.3e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 395       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 5.33e+08  |\n",
            "|    reward             | 3722491.5 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 4.72e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5023354.569050077\n",
            "Sharpe:  0.8475798128874913\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 2.01e+08  |\n",
            "|    reward             | 1328165.2 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 7.01e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 388       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 5.83e+08  |\n",
            "|    reward             | 3878249.8 |\n",
            "|    std                | 0.994     |\n",
            "|    value_loss         | 5.58e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5547010.511875912\n",
            "Sharpe:  0.8893687011369836\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 2.02e+08  |\n",
            "|    reward             | 1358257.9 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 6.03e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 387       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 3.57e+08  |\n",
            "|    reward             | 2173508.0 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 1.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5792895.726345668\n",
            "Sharpe:  0.9042416802304708\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.83e+08  |\n",
            "|    reward             | 1258028.1 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 4.89e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 3.48e+08  |\n",
            "|    reward             | 2278290.2 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 1.83e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5266903.76371002\n",
            "Sharpe:  0.8662425156086248\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 1.68e+08  |\n",
            "|    reward             | 1152574.2 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 5.02e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 2.93e+08  |\n",
            "|    reward             | 1969435.1 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 1.26e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 386       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 6.01e+08  |\n",
            "|    reward             | 3907561.5 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 5.57e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5268337.846483023\n",
            "Sharpe:  0.8637837279373303\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 1.81e+08  |\n",
            "|    reward             | 1163467.6 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 5.09e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 385       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 5.96e+08  |\n",
            "|    reward             | 4144955.2 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 5.92e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5154977.962694649\n",
            "Sharpe:  0.8482453579029904\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 1.79e+08  |\n",
            "|    reward             | 1112993.2 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 4.73e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 384       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 3.68e+08  |\n",
            "|    reward             | 2629754.0 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 2.3e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4631334.230920306\n",
            "Sharpe:  0.8034514332334414\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 373       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 1.61e+08  |\n",
            "|    reward             | 1097239.6 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 4.84e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 367       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 3.73e+08  |\n",
            "|    reward             | 2630117.0 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 2.13e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5525695.336058353\n",
            "Sharpe:  0.8791089366886125\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 367       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 48        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 1.85e+08  |\n",
            "|    reward             | 1224674.1 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 5.57e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 368       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 51        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 2.72e+08  |\n",
            "|    reward             | 1743043.0 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 1.2e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 369       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 54        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 6.73e+08  |\n",
            "|    reward             | 4422124.5 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 6.27e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4890846.62877289\n",
            "Sharpe:  0.8267179399321974\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 369       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 56        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1281913.8 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 5.63e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 370       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 59        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 4.11e+08  |\n",
            "|    reward             | 2935356.0 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 2.48e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5077862.094591463\n",
            "Sharpe:  0.8426840955689586\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 370       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 2.03e+08  |\n",
            "|    reward             | 1386933.1 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 6.01e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 371       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 64        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 5.41e+08  |\n",
            "|    reward             | 3307888.8 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 4.15e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5887160.671354392\n",
            "Sharpe:  0.9049512798080989\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 371       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 1.9e+08   |\n",
            "|    reward             | 1235246.6 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 6.05e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 372       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 69        |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 4.45e+08  |\n",
            "|    reward             | 2547882.0 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 3.08e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5424359.947955759\n",
            "Sharpe:  0.8664819760403772\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 372       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 1.89e+08  |\n",
            "|    reward             | 1136450.9 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 5.41e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 373       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 75        |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 2.65e+08  |\n",
            "|    reward             | 1878494.0 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 1.11e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5224505.668589185\n",
            "Sharpe:  0.8543005475135661\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 373       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 1.52e+08  |\n",
            "|    reward             | 1091151.4 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 3.83e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 373       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 2.22e+08  |\n",
            "|    reward             | 1696962.1 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 8.79e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 6e+08     |\n",
            "|    reward             | 3972489.8 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 5.99e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4827278.382308437\n",
            "Sharpe:  0.8163506885081813\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 1.62e+08  |\n",
            "|    reward             | 1030847.4 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 3.74e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 4.18e+08  |\n",
            "|    reward             | 3080883.8 |\n",
            "|    std                | 0.98      |\n",
            "|    value_loss         | 3.05e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4213761.346459339\n",
            "Sharpe:  0.7599654765632925\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 90        |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 1.91e+08  |\n",
            "|    reward             | 1315227.9 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 6.19e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 3.24e+08  |\n",
            "|    reward             | 2370668.8 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 1.85e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4574137.562005957\n",
            "Sharpe:  0.7972097129484974\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 374       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 1.87e+08  |\n",
            "|    reward             | 1286155.2 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 5.85e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 98        |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 3.53e+08  |\n",
            "|    reward             | 2149603.0 |\n",
            "|    std                | 0.978     |\n",
            "|    value_loss         | 1.85e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5046828.635741061\n",
            "Sharpe:  0.8423270235368053\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 1.75e+08  |\n",
            "|    reward             | 1197104.8 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 4.92e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 2.79e+08  |\n",
            "|    reward             | 1836351.5 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 1.32e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 106       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 6.82e+08  |\n",
            "|    reward             | 4944748.5 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 7.83e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5239572.402678294\n",
            "Sharpe:  0.8572333952011371\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 41000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | 1.59e+08  |\n",
            "|    reward             | 996026.06 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 4.4e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 111       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 7.41e+08  |\n",
            "|    reward             | 5062812.0 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 9.2e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5902873.083945341\n",
            "Sharpe:  0.9105576482044229\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 114       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 1.57e+08  |\n",
            "|    reward             | 1087995.1 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 4.24e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 117       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 4.01e+08  |\n",
            "|    reward             | 2676001.8 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 2.51e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4664028.327567282\n",
            "Sharpe:  0.8098110691992555\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 119       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 1.69e+08  |\n",
            "|    reward             | 1055285.9 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 4.1e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 3.93e+08  |\n",
            "|    reward             | 2671029.5 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 2.61e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5941386.144431585\n",
            "Sharpe:  0.9165562790298065\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 125       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 1.83e+08  |\n",
            "|    reward             | 1216391.4 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 5.67e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 2.74e+08  |\n",
            "|    reward             | 1925527.8 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 1.25e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 130       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 7.49e+08  |\n",
            "|    reward             | 5098707.0 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 9.15e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5386880.17547549\n",
            "Sharpe:  0.8695606462705775\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 375       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 133       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 1.74e+08  |\n",
            "|    reward             | 1099380.0 |\n",
            "|    std                | 0.975     |\n",
            "|    value_loss         | 4.75e+13  |\n",
            "-------------------------------------\n",
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.001, 'batch_size': 128}\n",
            "Using cuda device\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 480       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 4         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 4883576.0 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6114733.022209765\n",
            "Sharpe:  0.9246730334322475\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 429          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.789357e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.02e+15     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -4.01e-06    |\n",
            "|    reward               | 4167124.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.77e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5123991.04989815\n",
            "Sharpe:  0.8529040532241516\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 415          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.381903e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.76e+14     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -4.03e-06    |\n",
            "|    reward               | 3234899.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.6e+15      |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5649592.973972581\n",
            "Sharpe:  0.8956256587530314\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.683411e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.05e+14     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -4.28e-06    |\n",
            "|    reward               | 2400573.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.51e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5742220.649452671\n",
            "Sharpe:  0.905522381354658\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 404         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 7.82893e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 9.33e+14    |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -3.77e-06   |\n",
            "|    reward               | 2029550.4   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.86e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4543126.817567621\n",
            "Sharpe:  0.8005345060489022\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 401         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 30          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.96398e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 1.05e+15    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -4.05e-06   |\n",
            "|    reward               | 1958335.1   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.88e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5979706.004186755\n",
            "Sharpe:  0.9236402911845571\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 400           |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 35            |\n",
            "|    total_timesteps      | 14336         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.0244548e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 6.75e+14      |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -4.22e-06     |\n",
            "|    reward               | 1554415.6     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.44e+15      |\n",
            "-------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6158060.980251191\n",
            "Sharpe:  0.9338885511517875\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 398         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 41          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.58563e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 9.04e+14    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -3.53e-06   |\n",
            "|    reward               | 1201803.0   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 2.03e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5004856.094774272\n",
            "Sharpe:  0.8423371786448486\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 397          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.789357e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.14e+15     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -3.37e-06    |\n",
            "|    reward               | 1229863.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.38e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5086654.627378037\n",
            "Sharpe:  0.8467323030873155\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 395          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 51           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.061761e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.96e+14     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -3.76e-06    |\n",
            "|    reward               | 1122888.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.83e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5135521.381439758\n",
            "Sharpe:  0.8527947674547777\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 395          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.429641e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.24e+14     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -4.09e-06    |\n",
            "|    reward               | 1185580.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.78e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5310670.356381258\n",
            "Sharpe:  0.8677497561318588\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 395          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 62           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.789357e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.56e+14     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -4.18e-06    |\n",
            "|    reward               | 1144209.9    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.76e+15     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 384         |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 69          |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.20728e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 9.78e+14    |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -4.05e-06   |\n",
            "|    reward               | 4087323.5   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.88e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4733441.810586856\n",
            "Sharpe:  0.8203939421183721\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 383          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 74           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.945346e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.62e+14     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -5.14e-06    |\n",
            "|    reward               | 3210991.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.23e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5452959.831929229\n",
            "Sharpe:  0.8803395407647095\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 384          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.313226e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.53e+14     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -4.1e-06     |\n",
            "|    reward               | 3674521.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.48e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5437522.340485261\n",
            "Sharpe:  0.8766364298566034\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 384          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 85           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.487849e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.61e+14     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -4.26e-06    |\n",
            "|    reward               | 2343567.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.54e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4666614.2503047725\n",
            "Sharpe:  0.8137278635553845\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 384          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.934876e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.41e+14     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -4.14e-06    |\n",
            "|    reward               | 2538709.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.63e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5929419.936533417\n",
            "Sharpe:  0.9205911817168757\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 95           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.003553e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.04e+14     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -4.45e-06    |\n",
            "|    reward               | 2107742.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.46e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6398973.485159912\n",
            "Sharpe:  0.9505834862965121\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 385         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 9.34233e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 1.06e+15    |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -4.38e-06   |\n",
            "|    reward               | 1706383.6   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 2.1e+15     |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5439055.583363208\n",
            "Sharpe:  0.8762543658251889\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 375           |\n",
            "|    iterations           | 20            |\n",
            "|    time_elapsed         | 108           |\n",
            "|    total_timesteps      | 40960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 7.2759576e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | -2.38e-07     |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 9.63e+14      |\n",
            "|    n_updates            | 190           |\n",
            "|    policy_gradient_loss | -3.42e-06     |\n",
            "|    reward               | 1200791.4     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 2.33e+15      |\n",
            "-------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:973446.8317167734\n",
            "Sharpe:  -0.043120059810434604\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:987416.5496244207\n",
            "Sharpe:  0.026280195019090336\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "import pandas as pd\n",
        "from pypfopt import EfficientFrontier\n",
        "from pypfopt import risk_models\n",
        "from pypfopt import expected_returns\n",
        "from pypfopt import objective_functions\n",
        "from pyfolio import timeseries\n",
        "\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 1000000, \n",
        "    \"transaction_cost_pct\": 0, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": tech_indicator_list, \n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-1    \n",
        "}\n",
        "\n",
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
        "\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "print(type(env_train))\n",
        "\n",
        "agent = DRLAgent(env = env_train)\n",
        "\n",
        "for i in range(30):\n",
        "  print(f\"GO {i} iteration!!!!\")\n",
        "  A2C_PARAMS = {\"n_steps\": 10, \"ent_coef\": 0.005, \"learning_rate\": 0.0004}\n",
        "  model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)\n",
        "\n",
        "  trained_a2c = agent.train_model(model=model_a2c, \n",
        "                                  tb_log_name='a2c',\n",
        "                                  total_timesteps=50000)\n",
        "\n",
        "  agent = DRLAgent(env = env_train)\n",
        "  PPO_PARAMS = {\n",
        "      \"n_steps\": 2048,\n",
        "      \"ent_coef\": 0.005,\n",
        "      \"learning_rate\": 0.001,\n",
        "      \"batch_size\": 128,\n",
        "  }\n",
        "  model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)\n",
        "\n",
        "  trained_ppo = agent.train_model(model=model_ppo,\n",
        "                              tb_log_name='ppo',\n",
        "                              total_timesteps=40000)\n",
        "\n",
        "  trade = data_split(df,mid_date, end_date)\n",
        "  e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n",
        "\n",
        "  unique_tic = trade.tic.unique()\n",
        "  unique_trade_date = trade.date.unique()\n",
        "\n",
        "\n",
        "  df_daily_return_a2c, df_actions_a2c = DRLAgent.DRL_prediction(model=trained_a2c,\n",
        "                          environment = e_trade_gym)\n",
        "  df_daily_return_ppo, df_actions_ppo = DRLAgent.DRL_prediction(model=trained_ppo,\n",
        "                          environment = e_trade_gym)\n",
        "  time_ind = pd.Series(df_daily_return_a2c.date)\n",
        "  a2c_cumpod =(df_daily_return_a2c.daily_return+1).cumprod()-1\n",
        "  ppo_cumpod =(df_daily_return_ppo.daily_return+1).cumprod()-1\n",
        "  DRL_strat_a2c = convert_daily_return_to_pyfolio_ts(df_daily_return_a2c)\n",
        "  DRL_strat_ppo = convert_daily_return_to_pyfolio_ts(df_daily_return_ppo)\n",
        "\n",
        "  perf_func = timeseries.perf_stats \n",
        "  perf_stats_all_a2c = perf_func( returns=DRL_strat_a2c, \n",
        "                                factor_returns=DRL_strat_a2c, \n",
        "                                  positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "  perf_stats_all_ppo = perf_func( returns=DRL_strat_ppo, \n",
        "                                factor_returns=DRL_strat_ppo, \n",
        "                                  positions=None, transactions=None, turnover_denom=\"AGB\")\n",
        "\n",
        "  a2c_weights = extract_weights(df_actions_a2c)\n",
        "  ppo_weights = extract_weights(df_actions_ppo)\n",
        "\n",
        "  perf_stats_all_a2c.to_csv(\"./perf_stats_all_a2c_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1bO1p_PawDtsql6taNu_lWI6B_0UPveYm'}]})\n",
        "  f.SetContentFile(\"./perf_stats_all_a2c_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_actions_a2c.to_csv(\"./df_actions_a2c_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1vDZV5gKcX5E1ci0P2nxD_6MOaly2928C'}]})\n",
        "  f.SetContentFile(\"./df_actions_a2c_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_daily_return_a2c.to_csv(\"./df_daily_return_a2c_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1cIzlsVFuXrgVEVsncnzYD1utLuvrlGu2'}]})\n",
        "  f.SetContentFile(\"./df_daily_return_a2c_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  perf_stats_all_ppo.to_csv(\"./perf_stats_all_ppo_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1YGRCCbw6qdpFqRBwi_3d4ThZVH8-hCnT'}]})\n",
        "  f.SetContentFile(\"./perf_stats_all_ppo_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_actions_ppo.to_csv(\"./df_actions_ppo_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '1sa6d1aLl9AbqiUMGpUCMh4rywQAW7bRT'}]})\n",
        "  f.SetContentFile(\"./df_actions_ppo_\"+str(i)+'.csv')\n",
        "  f.Upload()\n",
        "\n",
        "  df_daily_return_ppo.to_csv(\"./df_daily_return_ppo_\"+str(i)+'.csv')\n",
        "  f = drive.CreateFile({'parents': [{'id': '13nbBnyqan8imPGEg5qgFkCfU-H2byb8F'}]})\n",
        "  f.SetContentFile(\"./df_daily_return_ppo_\"+str(i)+'.csv')\n",
        "  f.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTlOf8SJGdkl",
        "outputId": "373336e6-ecda-4f1d-968c-7ae81a3d6fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eKIu5UPlPnk"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* We use two DRL algorithms in FinRL library PPO andf A2C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdPe8uzflbXe"
      },
      "source": [
        "### Model 1: **A2C**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1tORf1fIcQ2",
        "outputId": "07559c11-0a2f-4c01-aa74-09e1d218cde4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 10, 'ent_coef': 0.005, 'learning_rate': 0.0004}\n",
            "Using cuda device\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DazEdrMpIdyz",
        "outputId": "c8303170-c493-43ba-f940-0e424042df45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 198       |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 2.05e+08  |\n",
            "|    reward             | 1326701.6 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 6.62e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 263       |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 7         |\n",
            "|    total_timesteps    | 2000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 5.95e+08  |\n",
            "|    reward             | 3916030.0 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 5.29e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5400127.758877084\n",
            "Sharpe:  0.877679103436335\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 290       |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 10        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 1.74e+08  |\n",
            "|    reward             | 1155804.6 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 5.31e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 309       |\n",
            "|    iterations         | 400       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 399       |\n",
            "|    policy_loss        | 5.62e+08  |\n",
            "|    reward             | 3502206.2 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 4.41e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4691442.649152003\n",
            "Sharpe:  0.819359098602763\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 319       |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 15        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 1.86e+08  |\n",
            "|    reward             | 1261025.1 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 5.19e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 329       |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 18        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | 3.2e+08   |\n",
            "|    reward             | 1889634.6 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 1.5e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4686925.275902159\n",
            "Sharpe:  0.8233101427254824\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 334       |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 1.83e+08  |\n",
            "|    reward             | 1323514.8 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 5.49e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 340       |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | 3.51e+08  |\n",
            "|    reward             | 2303136.8 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 1.88e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5620754.230040139\n",
            "Sharpe:  0.899505444773552\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 343       |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 1.95e+08  |\n",
            "|    reward             | 1138554.8 |\n",
            "|    std                | 0.992     |\n",
            "|    value_loss         | 4.95e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 347       |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 28        |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | 2.89e+08  |\n",
            "|    reward             | 1946041.2 |\n",
            "|    std                | 0.991     |\n",
            "|    value_loss         | 1.24e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 351       |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 31        |\n",
            "|    total_timesteps    | 11000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 7.34e+08  |\n",
            "|    reward             | 4829012.0 |\n",
            "|    std                | 0.99      |\n",
            "|    value_loss         | 8.47e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6370042.590121082\n",
            "Sharpe:  0.9476936412036805\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 352       |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 12000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 2e+08     |\n",
            "|    reward             | 1265364.6 |\n",
            "|    std                | 0.989     |\n",
            "|    value_loss         | 6.07e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 355       |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 36        |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 6.38e+08  |\n",
            "|    reward             | 4431548.0 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 6.83e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5633518.884305136\n",
            "Sharpe:  0.8975429664348511\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 355       |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 39        |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | 1.82e+08  |\n",
            "|    reward             | 1238332.4 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 6.04e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 356       |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 42        |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 4.48e+08  |\n",
            "|    reward             | 3025094.5 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 3.05e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5675173.195497834\n",
            "Sharpe:  0.9045103619186804\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 357       |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 44        |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 1.67e+08  |\n",
            "|    reward             | 1129278.8 |\n",
            "|    std                | 0.988     |\n",
            "|    value_loss         | 5.16e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 358       |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 3.61e+08  |\n",
            "|    reward             | 2732326.8 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 2.32e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5448924.14761388\n",
            "Sharpe:  0.885393627325533\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 358       |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 50        |\n",
            "|    total_timesteps    | 18000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 1.97e+08  |\n",
            "|    reward             | 1290213.9 |\n",
            "|    std                | 0.987     |\n",
            "|    value_loss         | 6.05e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 360       |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | 2.88e+08  |\n",
            "|    reward             | 1805307.6 |\n",
            "|    std                | 0.986     |\n",
            "|    value_loss         | 1.28e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 348       |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | 6.71e+08  |\n",
            "|    reward             | 4787574.0 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 7.44e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5224978.24639423\n",
            "Sharpe:  0.8675031551417882\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 349       |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 60        |\n",
            "|    total_timesteps    | 21000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 2.09e+08  |\n",
            "|    reward             | 1384638.1 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 6.83e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 351       |\n",
            "|    iterations         | 2200      |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 22000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28.1     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2199      |\n",
            "|    policy_loss        | 4.55e+08  |\n",
            "|    reward             | 3232412.5 |\n",
            "|    std                | 0.985     |\n",
            "|    value_loss         | 2.97e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5325685.138892668\n",
            "Sharpe:  0.8778126819902827\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 352       |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 1.84e+08  |\n",
            "|    reward             | 1337913.9 |\n",
            "|    std                | 0.984     |\n",
            "|    value_loss         | 5.7e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 353       |\n",
            "|    iterations         | 2400      |\n",
            "|    time_elapsed       | 67        |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2399      |\n",
            "|    policy_loss        | 4.87e+08  |\n",
            "|    reward             | 3229246.2 |\n",
            "|    std                | 0.983     |\n",
            "|    value_loss         | 3.81e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5516871.777554482\n",
            "Sharpe:  0.8962643913515486\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 353       |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 70        |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | 1.73e+08  |\n",
            "|    reward             | 1093920.8 |\n",
            "|    std                | 0.982     |\n",
            "|    value_loss         | 4.68e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 348       |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 74        |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 3.42e+08  |\n",
            "|    reward             | 2035170.2 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 1.91e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5236390.45396873\n",
            "Sharpe:  0.8776693096128255\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 346       |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 77        |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 1.72e+08  |\n",
            "|    reward             | 1121586.6 |\n",
            "|    std                | 0.981     |\n",
            "|    value_loss         | 5.21e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 347       |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 80        |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 3.23e+08  |\n",
            "|    reward             | 2271920.2 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 1.62e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5962029.056593428\n",
            "Sharpe:  0.9415960570339806\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 348       |\n",
            "|    iterations         | 2900      |\n",
            "|    time_elapsed       | 83        |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -28       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2899      |\n",
            "|    policy_loss        | 1.53e+08  |\n",
            "|    reward             | 1108179.6 |\n",
            "|    std                | 0.979     |\n",
            "|    value_loss         | 3.96e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 349       |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 85        |\n",
            "|    total_timesteps    | 30000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | 2.81e+08  |\n",
            "|    reward             | 2010714.9 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 1.3e+14   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 350       |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 88        |\n",
            "|    total_timesteps    | 31000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 7.8e+08   |\n",
            "|    reward             | 5251121.5 |\n",
            "|    std                | 0.978     |\n",
            "|    value_loss         | 1.01e+15  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6691059.659147242\n",
            "Sharpe:  0.9893935534057852\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 351       |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 91        |\n",
            "|    total_timesteps    | 32000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 1.93e+08  |\n",
            "|    reward             | 1324156.9 |\n",
            "|    std                | 0.977     |\n",
            "|    value_loss         | 6.15e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 352       |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 93        |\n",
            "|    total_timesteps    | 33000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 5.88e+08  |\n",
            "|    reward             | 3875679.0 |\n",
            "|    std                | 0.976     |\n",
            "|    value_loss         | 4.9e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5511295.840407943\n",
            "Sharpe:  0.9015977201750801\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 352       |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 96        |\n",
            "|    total_timesteps    | 34000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 1.85e+08  |\n",
            "|    reward             | 1243393.2 |\n",
            "|    std                | 0.974     |\n",
            "|    value_loss         | 5.86e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 353       |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 98        |\n",
            "|    total_timesteps    | 35000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | 3.21e+08  |\n",
            "|    reward             | 2371300.5 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 1.9e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5225568.719655052\n",
            "Sharpe:  0.8754577061579408\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 354       |\n",
            "|    iterations         | 3600      |\n",
            "|    time_elapsed       | 101       |\n",
            "|    total_timesteps    | 36000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3599      |\n",
            "|    policy_loss        | 1.8e+08   |\n",
            "|    reward             | 1241847.6 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 5.56e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 355       |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 104       |\n",
            "|    total_timesteps    | 37000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | 3.05e+08  |\n",
            "|    reward             | 1993652.5 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 1.6e+14   |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5145332.3817874575\n",
            "Sharpe:  0.8718793780703048\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 355       |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 107       |\n",
            "|    total_timesteps    | 38000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | 1.79e+08  |\n",
            "|    reward             | 1183903.6 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 4.9e+13   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 355       |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 109       |\n",
            "|    total_timesteps    | 39000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 2.67e+08  |\n",
            "|    reward             | 1707024.2 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 1.11e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 356       |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 112       |\n",
            "|    total_timesteps    | 40000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 7.44e+08  |\n",
            "|    reward             | 5119091.0 |\n",
            "|    std                | 0.973     |\n",
            "|    value_loss         | 8.56e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5639413.2213251535\n",
            "Sharpe:  0.9160691580145075\n",
            "=================================\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 356        |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 115        |\n",
            "|    total_timesteps    | 41000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -27.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0004     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 1.68e+08   |\n",
            "|    reward             | 1013043.94 |\n",
            "|    std                | 0.971      |\n",
            "|    value_loss         | 4.35e+13   |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 357       |\n",
            "|    iterations         | 4200      |\n",
            "|    time_elapsed       | 117       |\n",
            "|    total_timesteps    | 42000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4199      |\n",
            "|    policy_loss        | 6.08e+08  |\n",
            "|    reward             | 4124634.0 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 5.93e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5235009.261308165\n",
            "Sharpe:  0.8778413059829814\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 357       |\n",
            "|    iterations         | 4300      |\n",
            "|    time_elapsed       | 120       |\n",
            "|    total_timesteps    | 43000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4299      |\n",
            "|    policy_loss        | 1.94e+08  |\n",
            "|    reward             | 1253831.8 |\n",
            "|    std                | 0.972     |\n",
            "|    value_loss         | 5.36e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 357       |\n",
            "|    iterations         | 4400      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4399      |\n",
            "|    policy_loss        | 4.81e+08  |\n",
            "|    reward             | 3228915.2 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 3.65e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5876638.684745218\n",
            "Sharpe:  0.9327073972457269\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 358       |\n",
            "|    iterations         | 4500      |\n",
            "|    time_elapsed       | 125       |\n",
            "|    total_timesteps    | 45000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4499      |\n",
            "|    policy_loss        | 1.61e+08  |\n",
            "|    reward             | 1077682.0 |\n",
            "|    std                | 0.971     |\n",
            "|    value_loss         | 4.21e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 358       |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 128       |\n",
            "|    total_timesteps    | 46000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.8     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 3.93e+08  |\n",
            "|    reward             | 2544070.8 |\n",
            "|    std                | 0.97      |\n",
            "|    value_loss         | 2.39e+14  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5380335.160088545\n",
            "Sharpe:  0.9016014872958347\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 358       |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 131       |\n",
            "|    total_timesteps    | 47000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 1.84e+08  |\n",
            "|    reward             | 1220011.1 |\n",
            "|    std                | 0.969     |\n",
            "|    value_loss         | 5.77e+13  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 359       |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 133       |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | 2.77e+08  |\n",
            "|    reward             | 2071069.5 |\n",
            "|    std                | 0.968     |\n",
            "|    value_loss         | 1.42e+14  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 359       |\n",
            "|    iterations         | 4900      |\n",
            "|    time_elapsed       | 136       |\n",
            "|    total_timesteps    | 49000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4899      |\n",
            "|    policy_loss        | 9.79e+08  |\n",
            "|    reward             | 6304453.5 |\n",
            "|    std                | 0.969     |\n",
            "|    value_loss         | 1.38e+15  |\n",
            "-------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6509874.844967305\n",
            "Sharpe:  0.9880931846698545\n",
            "=================================\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 359       |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 139       |\n",
            "|    total_timesteps    | 50000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -27.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0004    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 2.3e+08   |\n",
            "|    reward             | 1412912.1 |\n",
            "|    std                | 0.97      |\n",
            "|    value_loss         | 8e+13     |\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvrqTro3lhAh"
      },
      "source": [
        "### Model 2: **PPO**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXta7jVKMhV",
        "outputId": "f972e8fc-7806-4463-be53-6d15cb1af3a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.001, 'batch_size': 128}\n",
            "Using cuda device\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5XlUIszKUGx",
        "outputId": "ddd555df-7ba2-4149-8dd1-ce5161dc3dff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 470       |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 4         |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 4472473.5 |\n",
            "----------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5884305.61316019\n",
            "Sharpe:  0.9142291759893856\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 424          |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 4096         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.683411e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.53e+14     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -3.94e-06    |\n",
            "|    reward               | 4235170.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.6e+15      |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5487775.2832631385\n",
            "Sharpe:  0.8812341079400812\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 409          |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 6144         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.614734e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.13e+14     |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -4.04e-06    |\n",
            "|    reward               | 3079688.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.62e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5313210.218651404\n",
            "Sharpe:  0.8655916856714488\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 403          |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.887138e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.1e+14      |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -4.54e-06    |\n",
            "|    reward               | 2259079.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.57e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5166362.234796482\n",
            "Sharpe:  0.8581831270239133\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 399          |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.731149e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.04e+14     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -3.9e-06     |\n",
            "|    reward               | 2051933.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.74e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5414259.784381009\n",
            "Sharpe:  0.8736796411761295\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 395         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 31          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.58563e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 7.66e+14    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -3.37e-06   |\n",
            "|    reward               | 1718573.4   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.65e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4978545.014617579\n",
            "Sharpe:  0.8429590218426963\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 394          |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 36           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.450581e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.08e+14     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -4e-06       |\n",
            "|    reward               | 1619904.5    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.67e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5953606.18359076\n",
            "Sharpe:  0.917476333809815\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 392           |\n",
            "|    iterations           | 8             |\n",
            "|    time_elapsed         | 41            |\n",
            "|    total_timesteps      | 16384         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 7.2759576e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | 2.38e-07      |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 7.33e+14      |\n",
            "|    n_updates            | 70            |\n",
            "|    policy_gradient_loss | -3.87e-06     |\n",
            "|    reward               | 1117877.9     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 1.58e+15      |\n",
            "-------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5972206.699445063\n",
            "Sharpe:  0.924066520604629\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 391          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 47           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.789357e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.11e+15     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -3.41e-06    |\n",
            "|    reward               | 1260850.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.41e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5572412.325802163\n",
            "Sharpe:  0.8910727875203582\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 390          |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.043127e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.25e+15     |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -3.07e-06    |\n",
            "|    reward               | 1122723.6    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.23e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5146536.54249735\n",
            "Sharpe:  0.8541984162957921\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 389          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 57           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.284122e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 1.14e+15     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -3.98e-06    |\n",
            "|    reward               | 1194785.9    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 2.1e+15      |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5232141.226289892\n",
            "Sharpe:  0.86463136152122\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 63           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.876668e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.64e+14     |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -3.62e-06    |\n",
            "|    reward               | 1170293.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.85e+15     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 68           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.429641e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.52e+14     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -3.51e-06    |\n",
            "|    reward               | 4555947.0    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.89e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5235426.678114886\n",
            "Sharpe:  0.8647955867638303\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 388          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 73           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.080395e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.6e+14      |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -4.12e-06    |\n",
            "|    reward               | 3390666.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.58e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5609333.1426116815\n",
            "Sharpe:  0.8933331317158633\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 387          |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.614734e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 8.31e+14     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -4.14e-06    |\n",
            "|    reward               | 3236273.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.67e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:4718941.47585185\n",
            "Sharpe:  0.8166859460704375\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 387          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.255018e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 7.06e+14     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -3.63e-06    |\n",
            "|    reward               | 2641528.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.48e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5914956.029954281\n",
            "Sharpe:  0.9155468654913134\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 385          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 90           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.614734e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 6.34e+14     |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -4.36e-06    |\n",
            "|    reward               | 2605943.2    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.41e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5439453.264301012\n",
            "Sharpe:  0.880061056481457\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 378          |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 97           |\n",
            "|    total_timesteps      | 36864        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.731149e-09 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -28.4        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.001        |\n",
            "|    loss                 | 9.33e+14     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -4.27e-06    |\n",
            "|    reward               | 2320005.8    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 1.95e+15     |\n",
            "------------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:6954445.313602251\n",
            "Sharpe:  0.9894373495516312\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 8.20728e-09 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -28.4       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.001       |\n",
            "|    loss                 | 1.1e+15     |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -3.84e-06   |\n",
            "|    reward               | 1761918.6   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.98e+15    |\n",
            "-----------------------------------------\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:5492767.163025924\n",
            "Sharpe:  0.8869500795287315\n",
            "=================================\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 379           |\n",
            "|    iterations           | 20            |\n",
            "|    time_elapsed         | 108           |\n",
            "|    total_timesteps      | 40960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.8102963e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -28.4         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.001         |\n",
            "|    loss                 | 1.25e+15      |\n",
            "|    n_updates            | 190           |\n",
            "|    policy_gradient_loss | -3.03e-06     |\n",
            "|    reward               | 1165737.5     |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 2.73e+15      |\n",
            "-------------------------------------------\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Ma6YpTlnuZ"
      },
      "source": [
        "## Back-Testing\n",
        "Assume that we have $1,000,000 initial capital at 2020-01-01. We use the PPO, A2C, SVM, Linear Regression, Decision Tree, Random Foreset models to trade Dow jones 30 constituent stocks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uas8U6k455sI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IY9FV6IZlcFf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjE0koq1SRW5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NMOUIHy3NHD",
        "outputId": "8710e597-5036-4820-c3ba-2fc6b43271b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (249, 8)\n",
            "Annual return         -0.133359\n",
            "Cumulative returns    -0.131881\n",
            "Annual volatility      0.197511\n",
            "Sharpe ratio          -0.628697\n",
            "Calmar ratio          -0.581320\n",
            "Stability              0.333872\n",
            "Max drawdown          -0.229408\n",
            "Omega ratio            0.904711\n",
            "Sortino ratio         -0.829164\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.794876\n",
            "Daily value at risk   -0.025377\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pyfolio\n",
        "%matplotlib inline\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts\n",
        "\n",
        "baseline_df = get_baseline(\n",
        "        ticker=\"^BVSP\", \n",
        "        start = mid_date,\n",
        "        end =  end_date)\n",
        "\n",
        "baseline_df_stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
        "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "bvsp_cumpod =(baseline_returns+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUcP0AmbPaFg",
        "outputId": "67470729-155c-4f3f-b346-55eb1a6917c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:958427.9690535984\n",
            "Sharpe:  -0.13198800843606437\n",
            "=================================\n",
            "hit end!\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:987852.5829020917\n",
            "Sharpe:  0.028641645608243976\n",
            "=================================\n",
            "hit end!\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF5xR6e_cZyG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_oj0bOGn9we",
        "outputId": "e246476e-0a4d-47b6-c822-b05fc7bd1629"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Annual return         -0.012293\n",
              "Cumulative returns    -0.012147\n",
              "Annual volatility      0.188706\n",
              "Sharpe ratio           0.028642\n",
              "Calmar ratio          -0.079296\n",
              "Stability              0.001464\n",
              "Max drawdown          -0.155025\n",
              "Omega ratio            1.004648\n",
              "Sortino ratio          0.039108\n",
              "Skew                  -0.263606\n",
              "Kurtosis               0.369760\n",
              "Tail ratio             0.820502\n",
              "Daily value at risk   -0.023753\n",
              "Alpha                  0.000000\n",
              "Beta                   1.000000\n",
              "dtype: float64"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjjPk3E_n_Dp",
        "outputId": "ee3bd907-bbc4-4065-e5ee-5c2786e8c4cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-0.04206221500315477"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_actions_a2c\n",
        "perf_stats_all_a2c\n",
        "df_daily_return_a2c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "KRwJ6V7dv6Xp",
        "outputId": "bea90bc8-f9f4-49d0-ecbc-3f9e0fb2437a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-14bb199d-7b44-45bd-b6a1-37632467b5ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABEV3.SA</th>\n",
              "      <th>B3SA3.SA</th>\n",
              "      <th>BBAS3.SA</th>\n",
              "      <th>BBDC3.SA</th>\n",
              "      <th>BBDC4.SA</th>\n",
              "      <th>CSAN3.SA</th>\n",
              "      <th>ENEV3.SA</th>\n",
              "      <th>EQTL3.SA</th>\n",
              "      <th>GGBR4.SA</th>\n",
              "      <th>ITSA4.SA</th>\n",
              "      <th>ITUB4.SA</th>\n",
              "      <th>JBSS3.SA</th>\n",
              "      <th>LREN3.SA</th>\n",
              "      <th>PETR3.SA</th>\n",
              "      <th>PETR4.SA</th>\n",
              "      <th>RADL3.SA</th>\n",
              "      <th>RENT3.SA</th>\n",
              "      <th>VALE3.SA</th>\n",
              "      <th>VIVT3.SA</th>\n",
              "      <th>WEGE3.SA</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2021-06-01</th>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.050000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-02</th>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.093281</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.065415</td>\n",
              "      <td>0.053051</td>\n",
              "      <td>0.055327</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.053457</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.088727</td>\n",
              "      <td>0.046698</td>\n",
              "      <td>0.036829</td>\n",
              "      <td>0.055866</td>\n",
              "      <td>0.083054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-04</th>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.086645</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.057825</td>\n",
              "      <td>0.054550</td>\n",
              "      <td>0.050374</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.048580</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.087328</td>\n",
              "      <td>0.055116</td>\n",
              "      <td>0.038701</td>\n",
              "      <td>0.050501</td>\n",
              "      <td>0.083370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-07</th>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.092155</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.054012</td>\n",
              "      <td>0.051692</td>\n",
              "      <td>0.052901</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.046586</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.100310</td>\n",
              "      <td>0.049292</td>\n",
              "      <td>0.037818</td>\n",
              "      <td>0.050289</td>\n",
              "      <td>0.086763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-06-08</th>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.088928</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.054633</td>\n",
              "      <td>0.050698</td>\n",
              "      <td>0.053786</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.044726</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.093991</td>\n",
              "      <td>0.049864</td>\n",
              "      <td>0.038571</td>\n",
              "      <td>0.051795</td>\n",
              "      <td>0.087301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-25</th>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.080372</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.063923</td>\n",
              "      <td>0.059335</td>\n",
              "      <td>0.056916</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.045314</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.082320</td>\n",
              "      <td>0.045348</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.061376</td>\n",
              "      <td>0.095763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-26</th>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.086104</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.069735</td>\n",
              "      <td>0.058349</td>\n",
              "      <td>0.050789</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.043814</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.078505</td>\n",
              "      <td>0.045217</td>\n",
              "      <td>0.036967</td>\n",
              "      <td>0.067933</td>\n",
              "      <td>0.092916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-27</th>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.089873</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.069945</td>\n",
              "      <td>0.059291</td>\n",
              "      <td>0.048773</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.046073</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.078420</td>\n",
              "      <td>0.045581</td>\n",
              "      <td>0.036608</td>\n",
              "      <td>0.064518</td>\n",
              "      <td>0.094834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-30</th>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.086912</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.071177</td>\n",
              "      <td>0.058510</td>\n",
              "      <td>0.048873</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.044999</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.078385</td>\n",
              "      <td>0.049361</td>\n",
              "      <td>0.037013</td>\n",
              "      <td>0.061764</td>\n",
              "      <td>0.092876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-31</th>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.098139</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.037493</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.070765</td>\n",
              "      <td>0.054036</td>\n",
              "      <td>0.054010</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.039443</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.074359</td>\n",
              "      <td>0.040231</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.078969</td>\n",
              "      <td>0.089924</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>249 rows × 20 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14bb199d-7b44-45bd-b6a1-37632467b5ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14bb199d-7b44-45bd-b6a1-37632467b5ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14bb199d-7b44-45bd-b6a1-37632467b5ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            ABEV3.SA  B3SA3.SA  BBAS3.SA  BBDC3.SA  BBDC4.SA  CSAN3.SA  \\\n",
              "date                                                                     \n",
              "2021-06-01  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000   \n",
              "2021-06-02  0.036829  0.093281  0.036829  0.036829  0.036829  0.036829   \n",
              "2021-06-04  0.038701  0.086645  0.038701  0.038701  0.038701  0.038701   \n",
              "2021-06-07  0.037818  0.092155  0.037818  0.037818  0.037818  0.037818   \n",
              "2021-06-08  0.038571  0.088928  0.038571  0.038571  0.038571  0.038571   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-05-25  0.037212  0.080372  0.037212  0.037212  0.037212  0.037212   \n",
              "2022-05-26  0.036967  0.086104  0.036967  0.036967  0.036967  0.036967   \n",
              "2022-05-27  0.036608  0.089873  0.036608  0.036608  0.036608  0.036608   \n",
              "2022-05-30  0.037013  0.086912  0.037013  0.037013  0.037013  0.037013   \n",
              "2022-05-31  0.036263  0.098139  0.036263  0.036263  0.036263  0.037493   \n",
              "\n",
              "            ENEV3.SA  EQTL3.SA  GGBR4.SA  ITSA4.SA  ITUB4.SA  JBSS3.SA  \\\n",
              "date                                                                     \n",
              "2021-06-01  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000   \n",
              "2021-06-02  0.036829  0.036829  0.036829  0.065415  0.053051  0.055327   \n",
              "2021-06-04  0.038701  0.038701  0.038701  0.057825  0.054550  0.050374   \n",
              "2021-06-07  0.037818  0.037818  0.037818  0.054012  0.051692  0.052901   \n",
              "2021-06-08  0.038571  0.038571  0.038571  0.054633  0.050698  0.053786   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-05-25  0.037212  0.037212  0.037212  0.063923  0.059335  0.056916   \n",
              "2022-05-26  0.036967  0.036967  0.036967  0.069735  0.058349  0.050789   \n",
              "2022-05-27  0.036608  0.036608  0.036608  0.069945  0.059291  0.048773   \n",
              "2022-05-30  0.037013  0.037013  0.037013  0.071177  0.058510  0.048873   \n",
              "2022-05-31  0.036263  0.036263  0.036263  0.070765  0.054036  0.054010   \n",
              "\n",
              "            LREN3.SA  PETR3.SA  PETR4.SA  RADL3.SA  RENT3.SA  VALE3.SA  \\\n",
              "date                                                                     \n",
              "2021-06-01  0.050000  0.050000  0.050000  0.050000  0.050000  0.050000   \n",
              "2021-06-02  0.036829  0.053457  0.036829  0.088727  0.046698  0.036829   \n",
              "2021-06-04  0.038701  0.048580  0.038701  0.087328  0.055116  0.038701   \n",
              "2021-06-07  0.037818  0.046586  0.037818  0.100310  0.049292  0.037818   \n",
              "2021-06-08  0.038571  0.044726  0.038571  0.093991  0.049864  0.038571   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-05-25  0.037212  0.045314  0.037212  0.082320  0.045348  0.037212   \n",
              "2022-05-26  0.036967  0.043814  0.036967  0.078505  0.045217  0.036967   \n",
              "2022-05-27  0.036608  0.046073  0.036608  0.078420  0.045581  0.036608   \n",
              "2022-05-30  0.037013  0.044999  0.037013  0.078385  0.049361  0.037013   \n",
              "2022-05-31  0.036263  0.039443  0.036263  0.074359  0.040231  0.036263   \n",
              "\n",
              "            VIVT3.SA  WEGE3.SA  \n",
              "date                            \n",
              "2021-06-01  0.050000  0.050000  \n",
              "2021-06-02  0.055866  0.083054  \n",
              "2021-06-04  0.050501  0.083370  \n",
              "2021-06-07  0.050289  0.086763  \n",
              "2021-06-08  0.051795  0.087301  \n",
              "...              ...       ...  \n",
              "2022-05-25  0.061376  0.095763  \n",
              "2022-05-26  0.067933  0.092916  \n",
              "2022-05-27  0.064518  0.094834  \n",
              "2022-05-30  0.061764  0.092876  \n",
              "2022-05-31  0.078969  0.089924  \n",
              "\n",
              "[249 rows x 20 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_actions_a2c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJh0jhrhiB4p"
      },
      "source": [
        "### Setup Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "365xaZTxiGaS"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZM3wFY8Vjjho"
      },
      "outputs": [],
      "source": [
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9I78zuOiJv9"
      },
      "outputs": [],
      "source": [
        "df_daily_return_a2c.to_csv(\"./df_daily_return_a2c_\"+now+\".csv\")\n",
        "f = drive.CreateFile({'parents': [{'id': '1AFEWTbUq7XXS3-6E7IzsovW_vMGoBuhD'}]})\n",
        "f.SetContentFile(\"./df_daily_return_a2c_\"+now+\".csv\")\n",
        "f.Upload()\n",
        "\n",
        "perf_stats_all_a2c.to_csv(\"./perf_stats_all_a2c_\"+now+\".csv\")\n",
        "f = drive.CreateFile({'parents': [{'id': '1AFEWTbUq7XXS3-6E7IzsovW_vMGoBuhD'}]})\n",
        "f.SetContentFile(\"./perf_stats_all_a2c_\"+now+\".csv\")\n",
        "f.Upload()\n",
        "\n",
        "df_actions_a2c.to_csv(\"./df_actions_a2c_\"+now+\".csv\")\n",
        "f = drive.CreateFile({'parents': [{'id': '1AFEWTbUq7XXS3-6E7IzsovW_vMGoBuhD'}]})\n",
        "f.SetContentFile(\"./df_actions_a2c_\"+now+\".csv\")\n",
        "f.Upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOIVYtyQmmdD"
      },
      "outputs": [],
      "source": [
        "df_daily_return_ppo.to_csv(\"./df_daily_return_ppo_\"+now+\".csv\")\n",
        "f = drive.CreateFile({'parents': [{'id': '1y9h865tgQZqVF4QmYUw7oauLZsXFDw9-'}]})\n",
        "f.SetContentFile(\"./df_daily_return_ppo_\"+now+\".csv\")\n",
        "f.Upload()\n",
        "\n",
        "perf_stats_all_ppo.to_csv(\"./perf_stats_all_ppo_\"+now+\".csv\")\n",
        "f = drive.CreateFile({'parents': [{'id': '1y9h865tgQZqVF4QmYUw7oauLZsXFDw9-'}]})\n",
        "f.SetContentFile(\"./perf_stats_all_ppo_\"+now+\".csv\")\n",
        "f.Upload()\n",
        "\n",
        "df_actions_ppo.to_csv(\"./df_actions_ppo_\"+now+\".csv\")\n",
        "f = drive.CreateFile({'parents': [{'id': '1y9h865tgQZqVF4QmYUw7oauLZsXFDw9-'}]})\n",
        "f.SetContentFile(\"./df_actions_ppo_\"+now+\".csv\")\n",
        "f.Upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElfXZCQb1Thv"
      },
      "source": [
        "## Machine Learning Models\n",
        "\n",
        "We trained the machine learning models with technical indicators: MACD, RSI, CCI, DX[texto do link](https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56nqKfFAR6m_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "\n",
        "def prepare_data(trainData):\n",
        "  train_date = sorted(set(trainData.date.values))\n",
        "  X = []\n",
        "  for i in range(0, len(train_date) - 1):\n",
        "    d = train_date[i]\n",
        "    d_next = train_date[i+1]\n",
        "    y = train.loc[train['date'] == d_next].return_list.iloc[0].loc[d_next].reset_index()\n",
        "    y.columns = ['tic', 'return']\n",
        "    x = train.loc[train['date'] == d][['tic','macd','rsi_30','cci_30','dx_30']]\n",
        "    train_piece = pd.merge(x, y, on = 'tic')\n",
        "    train_piece['date'] = [d] * len(train_piece)\n",
        "    X += [train_piece]\n",
        "  trainDataML = pd.concat(X)\n",
        "  X = trainDataML[tech_indicator_list].values\n",
        "  Y = trainDataML[['return']].values\n",
        "\n",
        "  return X, Y\n",
        "\n",
        "train_X, train_Y = prepare_data(train)\n",
        "rf_model = RandomForestRegressor(max_depth = 35,  min_samples_split = 10, random_state = 0).fit(train_X, train_Y.reshape(-1))\n",
        "dt_model = DecisionTreeRegressor(random_state = 0, max_depth=35, min_samples_split = 10 ).fit(train_X, train_Y.reshape(-1))\n",
        "svm_model =  SVR(epsilon=0.14).fit(train_X, train_Y.reshape(-1))\n",
        "lr_model = LinearRegression().fit(train_X, train_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIu0h0v-274U",
        "outputId": "72b9c1b4-2353-4777-f2b1-92497218c2c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Annual return          0.175887\n",
            "Cumulative returns     0.209627\n",
            "Annual volatility      0.423552\n",
            "Sharpe ratio           0.592017\n",
            "Calmar ratio           0.759039\n",
            "Stability              0.623836\n",
            "Max drawdown          -0.231723\n",
            "Omega ratio            1.104689\n",
            "Sortino ratio          0.967516\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.352546\n",
            "Daily value at risk   -0.052368\n",
            "dtype: float64\n",
            "Annual return          0.594963\n",
            "Cumulative returns     0.730420\n",
            "Annual volatility      0.293273\n",
            "Sharpe ratio           1.741683\n",
            "Calmar ratio           5.426880\n",
            "Stability              0.909640\n",
            "Max drawdown          -0.109633\n",
            "Omega ratio            1.386225\n",
            "Sortino ratio          3.179875\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.283427\n",
            "Daily value at risk   -0.034922\n",
            "dtype: float64\n",
            "Annual return          0.299888\n",
            "Cumulative returns     0.360800\n",
            "Annual volatility      0.150475\n",
            "Sharpe ratio           1.824696\n",
            "Calmar ratio           4.774179\n",
            "Stability              0.922028\n",
            "Max drawdown          -0.062815\n",
            "Omega ratio            1.357449\n",
            "Sortino ratio          2.875551\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.232376\n",
            "Daily value at risk   -0.017868\n",
            "dtype: float64\n",
            "Annual return          0.106791\n",
            "Cumulative returns     0.126573\n",
            "Annual volatility      0.389401\n",
            "Sharpe ratio           0.452846\n",
            "Calmar ratio           0.440612\n",
            "Stability              0.628956\n",
            "Max drawdown          -0.242369\n",
            "Omega ratio            1.081137\n",
            "Sortino ratio          0.728432\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.154242\n",
            "Daily value at risk   -0.048360\n",
            "dtype: float64\n",
            "Annual return            2793.780901\n",
            "Cumulative returns      11169.973656\n",
            "Annual volatility           0.423453\n",
            "Sharpe ratio               19.296122\n",
            "Calmar ratio           160680.821323\n",
            "Stability                   0.987983\n",
            "Max drawdown               -0.017387\n",
            "Omega ratio               159.636030\n",
            "Sortino ratio             330.672331\n",
            "Skew                             NaN\n",
            "Kurtosis                         NaN\n",
            "Tail ratio                 11.004182\n",
            "Daily value at risk        -0.020925\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "def output_predict(model, reference_model = False):\n",
        "  meta_coefficient = {\"date\":[], \"weights\":[]}\n",
        "\n",
        "  portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
        "  initial_capital = 1000000\n",
        "  portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
        "\n",
        "  for i in range(len(unique_trade_date) - 1):\n",
        "      \n",
        "      current_date = unique_trade_date[i]\n",
        "      next_date = unique_trade_date[i+1]\n",
        "      df_current = df[df.date==current_date].reset_index(drop=True)\n",
        "      tics = df_current['tic'].values\n",
        "      features = df_current[tech_indicator_list].values\n",
        "      df_next = df[df.date==next_date].reset_index(drop=True)\n",
        "      if not reference_model:\n",
        "        predicted_y = model.predict(features)      \n",
        "        mu = predicted_y\n",
        "        Sigma = risk_models.sample_cov(df_current.return_list[0], returns_data=True)\n",
        "      else:\n",
        "        mu = df_next.return_list[0].loc[next_date].values\n",
        "        Sigma = risk_models.sample_cov(df_next.return_list[0], returns_data=True)\n",
        "      predicted_y_df = pd.DataFrame({\"tic\":tics.reshape(-1,), \"predicted_y\":mu.reshape(-1,)})\n",
        "      min_weight, max_weight = 0, 1\n",
        "      ef = EfficientFrontier(mu, Sigma)\n",
        "      weights = ef.nonconvex_objective(\n",
        "          objective_functions.sharpe_ratio,\n",
        "          objective_args=(ef.expected_returns, ef.cov_matrix),\n",
        "          weights_sum_to_one=True,\n",
        "          constraints=[\n",
        "              {\"type\": \"ineq\", \"fun\": lambda w: w - min_weight},  # greater than min_weight\n",
        "              {\"type\": \"ineq\", \"fun\": lambda w: max_weight - w},  # less than max_weight\n",
        "          ],\n",
        "      )\n",
        "      \n",
        "      weight_df = {\"tic\":[], \"weight\":[]}\n",
        "      meta_coefficient[\"date\"] += [current_date]\n",
        "      # it = 0\n",
        "      for item in weights:\n",
        "        weight_df['tic'] += [item]\n",
        "        weight_df['weight'] += [weights[item]]\n",
        "      \n",
        "      weight_df = pd.DataFrame(weight_df).merge(predicted_y_df, on = ['tic'])\n",
        "      meta_coefficient[\"weights\"] += [weight_df]\n",
        "      cap = portfolio.iloc[0, i]\n",
        "      #current cash invested for each stock\n",
        "      current_cash = [element * cap for element in list(weights.values())]\n",
        "      # current held shares\n",
        "      current_shares = list(np.array(current_cash) / np.array(df_current.close))\n",
        "      # next time period price\n",
        "      next_price = np.array(df_next.close)\n",
        "      portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
        "      \n",
        "  portfolio=portfolio.T\n",
        "  portfolio.columns = ['account_value']\n",
        "  portfolio = portfolio.reset_index()\n",
        "  portfolio.columns = ['date', 'account_value']\n",
        "  stats = backtest_stats(portfolio, value_col_name = 'account_value')\n",
        "  portfolio_cumprod =(portfolio.account_value.pct_change()+1).cumprod()-1\n",
        "\n",
        "  return portfolio, stats, portfolio_cumprod, pd.DataFrame(meta_coefficient)\n",
        "\n",
        "lr_portfolio, lr_stats, lr_cumprod, lr_weights = output_predict(lr_model)\n",
        "dt_portfolio, dt_stats, dt_cumprod, dt_weights = output_predict(dt_model)\n",
        "svm_portfolio, svm_stats, svm_cumprod, svm_weights = output_predict(svm_model)\n",
        "rf_portfolio, rf_stats, rf_cumprod, rf_weights = output_predict(rf_model)\n",
        "reference_portfolio, reference_stats, reference_cumprod, reference_weights = output_predict(None, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_pDu_152D2e"
      },
      "source": [
        "# Part 7: Explanation Method Implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzzeU46e2kxy"
      },
      "source": [
        "### Integrated Gradient\n",
        ">* Reference: [Integrated Gradients](https://www.tensorflow.org/tutorials/interpretability/integrated_gradients)\n",
        "\n",
        "Implement the explanation method using integrated gradients and regression coefficients.\n",
        "The formula for Integrated Gradients is as follows:\n",
        "\n",
        "$IntegratedGradients_{i}(x) ::= (x_{i} - x'_{i})\\times\\int_{\\alpha=0}^1\\frac{\\partial F(x'+\\alpha \\times (x - x'))}{\\partial x_i}{d\\alpha}$\n",
        "\n",
        "where:\n",
        "\n",
        "$_{i}$ = feature   \n",
        "$x$ = input  \n",
        "$x'$ = baseline   \n",
        "$\\alpha$ = interpolation constant to perturb features by\n",
        "\n",
        "\n",
        "In practice, computing a definite integral is not always numerically possible and can be computationally costly, so you compute the following numerical approximation:\n",
        "\n",
        "$IntegratedGrads^{approx}_{i}(x)::=(x_{i}-x'_{i})\\times\\sum_{k=1}^{m}\\frac{\\partial F(x' + \\frac{k}{m}\\times(x - x'))}{\\partial x_{i}} \\times \\frac{1}{m}$\n",
        "\n",
        "where:\n",
        "\n",
        "$_{i}$ = feature (individual pixel)  \n",
        "$x$ = input (image tensor)  \n",
        "$x'$ = baseline (image tensor)  \n",
        "$k$ = scaled feature perturbation constant  \n",
        "$m$ = number of steps in the Riemann sum approximation of the integral  \n",
        "$(x_{i}-x'_{i})$ = a term for the difference from the baseline. This is necessary to scale the integrated gradients and keep them in terms of the original image. The path from the baseline image to the input is in pixel space. Since with IG you are integrating in a straight line (linear transformation) this ends up being roughly equivalent to the integral term of the derivative of the interpolated image function with respect to $\\alpha$ with enough steps. The integral sums each pixel's gradient times the change in the pixel along the path. It's simpler to implement this integration as uniform steps from one image to the other, substituting $x := (x' + \\alpha(x-x'))$. So the change of variables gives $dx = (x-x')d\\alpha$. The $(x-x')$ term is constant and is factored out of the integral."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_UAJ9eYPtiu"
      },
      "outputs": [],
      "source": [
        "def calculate_gradient(model, interpolated_input, actions,  feature_idx, stock_idx, h = 1e-1):\n",
        "  forward_input = interpolated_input\n",
        "  forward_input[feature_idx + stock_dimension][stock_idx] += h\n",
        "  forward_Q = model.policy.evaluate_actions(torch.cuda.FloatTensor(forward_input).reshape(-1,stock_dimension*(stock_dimension + feature_dimension)), torch.cuda.FloatTensor(actions).reshape(-1,stock_dimension))\n",
        "  interpolated_Q = model.policy.evaluate_actions(torch.cuda.FloatTensor(interpolated_input).reshape(-1,stock_dimension*(stock_dimension + feature_dimension)), torch.cuda.FloatTensor(actions).reshape(-1,stock_dimension))\n",
        "  forward_Q = forward_Q[0].detach().cpu().numpy()[0]\n",
        "  interpolated_Q = interpolated_Q[0].detach().cpu().numpy()[0]\n",
        "  return (forward_Q - interpolated_Q) / h"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY_q0OoF33dB"
      },
      "outputs": [],
      "source": [
        "import copy \n",
        "meta_Q = {\"date\":[], \"feature\":[], \"Saliency Map\":[], \"algo\":[]}\n",
        "\n",
        "for algo in {\"A2C\", \"PPO\"}:\n",
        "  if algo == \"A2C\":\n",
        "    prec_step = 1e-2\n",
        "  else:\n",
        "    prec_step = 1e-1\n",
        "\n",
        "  model = eval(\"trained_\" + algo.lower())\n",
        "  df_actions = eval(\"df_actions_\" + algo.lower())\n",
        "  for i in range(len(unique_trade_date)-1):\n",
        "    date = unique_trade_date[i]\n",
        "    covs = trade[trade['date'] == date].cov_list.iloc[0]\n",
        "    features = trade[trade['date'] == date][tech_indicator_list].values # N x K\n",
        "    actions = df_actions.loc[date].values\n",
        "   \n",
        "    for feature_idx in range(len(tech_indicator_list)):\n",
        "      \n",
        "      int_grad_per_feature = 0\n",
        "      for stock_idx in range(features.shape[0]):#N\n",
        "        \n",
        "        int_grad_per_stock = 0\n",
        "        avg_interpolated_grad = 0\n",
        "        for alpha in range(1, 51):\n",
        "          scale = 1/50\n",
        "          baseline_features = copy.deepcopy(features)\n",
        "          baseline_noise = np.random.normal(0, 1, stock_dimension)\n",
        "          baseline_features[:,feature_idx] = [0] * stock_dimension\n",
        "          interpolated_features = baseline_features + scale * alpha * (features - baseline_features) # N x K\n",
        "          interpolated_input = np.append(covs, interpolated_features.T, axis = 0)\n",
        "          interpolated_gradient = calculate_gradient(model, interpolated_input, actions, feature_idx, stock_idx, h = prec_step)[0]\n",
        "          \n",
        "          avg_interpolated_grad += interpolated_gradient * scale\n",
        "        int_grad_per_stock = (features[stock_idx][feature_idx] - 0) * avg_interpolated_grad\n",
        "        int_grad_per_feature += int_grad_per_stock\n",
        "      \n",
        "      meta_Q['date'] += [date]\n",
        "      meta_Q['algo'] += [algo]\n",
        "      meta_Q['feature'] += [tech_indicator_list[feature_idx]]\n",
        "      meta_Q['Saliency Map'] += [int_grad_per_feature]\n",
        "\n",
        "meta_Q = pd.DataFrame(meta_Q)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI0UkiCb2pLD"
      },
      "source": [
        "### Regression Coefficient\n",
        "Implement the linear regression to measure the feature weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNHzRWPvQIsu"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "meta_score_coef = {\"date\":[], \"coef\":[], \"algo\":[]}\n",
        "\n",
        "for algo in [\"LR\", \"RF\", \"Reference Model\", \"SVM\", \"DT\", \"A2C\", \"PPO\"]:\n",
        "  if algo == \"LR\":\n",
        "    weights = lr_weights\n",
        "  elif algo == \"RF\":\n",
        "    weights = rf_weights\n",
        "  elif algo == \"DT\":\n",
        "    weights = dt_weights\n",
        "  elif algo == \"SVM\":\n",
        "    weights = svm_weights\n",
        "  elif algo == \"A2C\":\n",
        "    weights = a2c_weights\n",
        "  elif algo == \"PPO\":\n",
        "    weights = ppo_weights\n",
        "  else:\n",
        "    weights = reference_weights\n",
        "\n",
        "  for i in range(len(unique_trade_date) - 1):\n",
        "    date = unique_trade_date[i]\n",
        "    next_date = unique_trade_date[i+1]\n",
        "    df_temp = df[df.date==date].reset_index(drop=True)\n",
        "    df_temp_next = df[df.date==next_date].reset_index(drop=True)\n",
        "    weight_piece = weights[weights.date == date].iloc[0]['weights']\n",
        "    piece_return = pd.DataFrame(df_temp_next.return_list.iloc[0].loc[next_date]).reset_index()\n",
        "    piece_return.columns = ['tic', 'return']\n",
        "    X = df_temp[['macd','rsi_30', 'cci_30', 'dx_30', 'tic']]\n",
        "    X_next = df_temp_next[['macd','rsi_30', 'cci_30', 'dx_30', 'tic']]\n",
        "    piece = weight_piece.merge(X, on = 'tic').merge(piece_return, on = 'tic')\n",
        "    piece['Y'] = piece['return'] * piece['weight']\n",
        "    X = piece[['macd','rsi_30', 'cci_30', 'dx_30']]\n",
        "    X = sm.add_constant(X)\n",
        "    Y = piece[['Y']]\n",
        "    model = sm.OLS(Y,X)\n",
        "    results = model.fit()\n",
        "    meta_score_coef[\"coef\"] += [(X * results.params).sum(axis = 0)]\n",
        "    meta_score_coef[\"date\"] += [date]\n",
        "    meta_score_coef[\"algo\"] += [algo]\n",
        "\n",
        "meta_score_coef = pd.DataFrame(meta_score_coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaCnRr2K4DuP"
      },
      "source": [
        "### Correlation Coefficient\n",
        "Calculate the  sing-step and multi-step correlation coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKWHxdK-QQxU"
      },
      "outputs": [],
      "source": [
        "performance_score = {\"date\":[], \"algo\":[], \"score\":[]}\n",
        "\n",
        "for i in range(0, len(unique_trade_date)):\n",
        "  date_ = unique_trade_date[i]\n",
        "  if len(meta_score_coef[(meta_score_coef['date'] == date_)]) == 0:\n",
        "    continue \n",
        "  lr_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'LR')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  rf_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'RF')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  reference_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'Reference Model')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  dt_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'DT')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  svm_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'SVM')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "\n",
        "  saliency_coef_a2c = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"A2C\")]['Saliency Map'].values\n",
        "  saliency_coef_ppo = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"PPO\")]['Saliency Map'].values\n",
        "\n",
        "  lr_score = np.corrcoef(lr_coef, reference_coef)[0][1]\n",
        "  rf_score = np.corrcoef(rf_coef, reference_coef)[0][1]\n",
        "  dt_score = np.corrcoef(dt_coef, reference_coef)[0][1]\n",
        "  svm_score = np.corrcoef(svm_coef, reference_coef)[0][1]\n",
        "  saliency_score_a2c = np.corrcoef(saliency_coef_a2c, reference_coef)[0][1]\n",
        "  saliency_score_ppo = np.corrcoef(saliency_coef_ppo, reference_coef)[0][1]\n",
        "\n",
        "  for algo in [\"LR\",\"A2C\",\"PPO\",\"RF\",\"DT\", \"SVM\"]:\n",
        "    performance_score[\"date\"] += [date_]\n",
        "    performance_score[\"algo\"] += [algo]\n",
        "    if algo == \"LR\":\n",
        "      score = lr_score \n",
        "    elif algo == \"RF\":\n",
        "      score = rf_score\n",
        "    elif algo == \"DT\":\n",
        "      score = dt_score\n",
        "    elif algo == \"A2C\":\n",
        "      score = saliency_score_a2c\n",
        "    elif algo == \"SVM\":\n",
        "      score = svm_score\n",
        "    else:\n",
        "      score = saliency_score_ppo\n",
        "    performance_score[\"score\"] += [score]\n",
        "\n",
        "performance_score = pd.DataFrame(performance_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em0Dx9p_kwrR"
      },
      "outputs": [],
      "source": [
        "multi_performance_score = {\"date\":[], \"algo\":[], \"score\":[]}\n",
        "window = 20\n",
        "for i in range(len(unique_trade_date) - window ):\n",
        "  date_ = unique_trade_date[i]\n",
        "  if len(meta_score_coef[(meta_score_coef['date'] == date_)]) == 0:\n",
        "    continue \n",
        "  lr_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'LR')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  rf_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'RF')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  reference_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'Reference Model')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  for w in range(1, window):\n",
        "      date_f = unique_trade_date[i + w]\n",
        "      prx_coef = meta_score_coef[(meta_score_coef['date'] == date_f) & (meta_score_coef['algo'] == 'Reference Model')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "      reference_coef += prx_coef\n",
        "  reference_coef = reference_coef / window\n",
        "  dt_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'DT')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  svm_coef = meta_score_coef[(meta_score_coef['date'] == date_) & (meta_score_coef['algo'] == 'SVM')]['coef'].values[0][['macd','rsi_30','cci_30','dx_30']].values\n",
        "  saliency_coef_a2c = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"A2C\")]['Saliency Map'].values\n",
        "  saliency_coef_ppo = meta_Q[(meta_Q['date'] == date_) & (meta_Q['algo'] == \"PPO\")]['Saliency Map'].values\n",
        "  lr_score = np.corrcoef(lr_coef, reference_coef)[0][1]\n",
        "  rf_score = np.corrcoef(rf_coef, reference_coef)[0][1]\n",
        "  dt_score = np.corrcoef(dt_coef, reference_coef)[0][1]\n",
        "  svm_score = np.corrcoef(svm_coef, reference_coef)[0][1]\n",
        "  saliency_score_a2c = np.corrcoef(saliency_coef_a2c, reference_coef)[0][1]\n",
        "  saliency_score_ppo = np.corrcoef(saliency_coef_ppo, reference_coef)[0][1]\n",
        "\n",
        "  for algo in [\"LR\", \"A2C\", \"RF\", \"PPO\", \"DT\", \"SVM\"]:\n",
        "    multi_performance_score[\"date\"] += [date_]\n",
        "    multi_performance_score[\"algo\"] += [algo]\n",
        "    if algo == \"LR\":\n",
        "      score = lr_score \n",
        "    elif algo == \"RF\":\n",
        "      score = rf_score\n",
        "    elif algo == \"DT\":\n",
        "      score = dt_score\n",
        "    elif algo == \"A2C\":\n",
        "      score = saliency_score_a2c\n",
        "    elif algo == \"SVM\":\n",
        "      score = svm_score\n",
        "    else:\n",
        "      score = saliency_score_ppo\n",
        "    multi_performance_score[\"score\"] += [score]\n",
        "\n",
        "multi_performance_score = pd.DataFrame(multi_performance_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yeGe06I3gGj"
      },
      "source": [
        "### Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDCuI-85fBgB"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "trace1_portfolio = go.Scatter(x = time_ind, y = a2c_cumpod, mode = 'lines', name = 'A2C')\n",
        "trace2_portfolio = go.Scatter(x = time_ind, y = ppo_cumpod, mode = 'lines', name = 'PPO')\n",
        "trace3_portfolio = go.Scatter(x = time_ind, y = dji_cumpod, mode = 'lines', name = 'DJIA')\n",
        "trace4_portfolio = go.Scatter(x = time_ind, y = lr_cumprod, mode = 'lines', name = 'LR')\n",
        "trace5_portfolio = go.Scatter(x = time_ind, y = rf_cumprod, mode = 'lines', name = 'RF')\n",
        "trace6_portfolio = go.Scatter(x = time_ind, y = dt_cumprod, mode = 'lines', name = 'DT')\n",
        "trace7_portfolio = go.Scatter(x = time_ind, y = svm_cumprod, mode = 'lines', name = 'SVM')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XClvP1WifJB_"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(trace1_portfolio)\n",
        "fig.add_trace(trace2_portfolio)\n",
        "\n",
        "fig.add_trace(trace3_portfolio)\n",
        "\n",
        "fig.add_trace(trace4_portfolio)\n",
        "fig.add_trace(trace5_portfolio)\n",
        "fig.add_trace(trace6_portfolio)\n",
        "fig.add_trace(trace7_portfolio)\n",
        "\n",
        "fig.update_layout(\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1,\n",
        "        traceorder=\"normal\",\n",
        "        font=dict(\n",
        "            family=\"sans-serif\",\n",
        "            size=15,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        bgcolor=\"White\",\n",
        "        bordercolor=\"white\",\n",
        "        borderwidth=2\n",
        "        \n",
        "    ),\n",
        ")\n",
        "fig.update_layout(title={\n",
        "        #'text': \"Cumulative Return using FinRL\",\n",
        "        'y':0.85,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'})\n",
        "\n",
        "fig.update_layout(\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis = dict(titlefont = dict(size = 30), title = \"Cumulative Return\"),\n",
        "    font=dict(\n",
        "        size=40,\n",
        "    ),\n",
        ")\n",
        "fig.update_layout(font_size = 20)\n",
        "fig.update_traces(line=dict(width=2))\n",
        "\n",
        "fig.update_xaxes(showline=True, linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0WhtMDgHz1p"
      },
      "source": [
        "#### We found that A2C and PPO succeeded in the portfoli management task and is better than all other algorithms/benchmark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxlehwfPfUMx"
      },
      "outputs": [],
      "source": [
        "meta_score = {\"Annual return\":[], \"Annual volatility\":[], \"Max drawdown\":[], \"Sharpe ratio\":[], \"Algorithm\":[], \"Calmar ratio\":[]}\n",
        "for name in [\"LR\", \"A2C\", \"RF\", \"Reference Model\", \"PPO\", \"SVM\", \"DT\", \"DJI\"]:\n",
        "  if name == \"DT\":\n",
        "    annualreturn = dt_stats[\"Annual return\"]\n",
        "    annualvol = dt_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = dt_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = dt_stats[\"Max drawdown\"]\n",
        "    calmarratio = dt_stats[\"Calmar ratio\"]\n",
        "  elif name == \"LR\":\n",
        "    annualreturn = lr_stats[\"Annual return\"]\n",
        "    annualvol = lr_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = lr_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = lr_stats[\"Max drawdown\"]\n",
        "    calmarratio = lr_stats[\"Calmar ratio\"]\n",
        "  elif name == \"SVM\":\n",
        "    annualreturn = svm_stats[\"Annual return\"]\n",
        "    annualvol = svm_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = svm_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = svm_stats[\"Max drawdown\"]\n",
        "    calmarratio = svm_stats[\"Calmar ratio\"]\n",
        "  elif name == \"RF\":\n",
        "    annualreturn = rf_stats[\"Annual return\"]\n",
        "    annualvol = rf_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = rf_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = rf_stats[\"Max drawdown\"]\n",
        "    calmarratio = rf_stats[\"Calmar ratio\"]\n",
        "  elif name == \"Reference Model\":\n",
        "    annualreturn = reference_stats[\"Annual return\"]\n",
        "    annualvol = reference_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = reference_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = reference_stats[\"Max drawdown\"]\n",
        "    calmarratio = reference_stats[\"Calmar ratio\"]\n",
        "  elif name == \"PPO\":\n",
        "    annualreturn = perf_stats_all_ppo[\"Annual return\"]\n",
        "    annualvol = perf_stats_all_ppo[\"Annual volatility\"]\n",
        "    sharpeRatio = perf_stats_all_ppo[\"Sharpe ratio\"]\n",
        "    maxdradown = perf_stats_all_ppo[\"Max drawdown\"]\n",
        "    calmarratio = perf_stats_all_ppo[\"Calmar ratio\"]\n",
        "  elif name == \"DJI\":\n",
        "    annualreturn = baseline_df_stats[\"Annual return\"]\n",
        "    annualvol = baseline_df_stats[\"Annual volatility\"]\n",
        "    sharpeRatio = baseline_df_stats[\"Sharpe ratio\"]\n",
        "    maxdradown = baseline_df_stats[\"Max drawdown\"]\n",
        "    calmarratio = baseline_df_stats[\"Calmar ratio\"]\n",
        "  else:\n",
        "    annualreturn = perf_stats_all_a2c[\"Annual return\"]\n",
        "    annualvol = perf_stats_all_a2c[\"Annual volatility\"]\n",
        "    sharpeRatio = perf_stats_all_a2c[\"Sharpe ratio\"]\n",
        "    maxdradown = perf_stats_all_a2c[\"Max drawdown\"]\n",
        "    calmarratio = perf_stats_all_a2c[\"Calmar ratio\"]\n",
        "  meta_score[\"Algorithm\"] += [name]\n",
        "  meta_score[\"Annual return\"] += [annualreturn]\n",
        "  meta_score[\"Annual volatility\"] += [annualvol]\n",
        "  meta_score[\"Max drawdown\"] += [maxdradown]\n",
        "  meta_score[\"Sharpe ratio\"] += [sharpeRatio]\n",
        "  meta_score[\"Calmar ratio\"] += [calmarratio]\n",
        "\n",
        "meta_score = pd.DataFrame(meta_score).sort_values(\"Sharpe ratio\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7sK4kM8QyEu"
      },
      "outputs": [],
      "source": [
        "postiveRatio = pd.DataFrame(performance_score.groupby(\"algo\").apply(lambda x : np.mean(x['score'])))\n",
        "\n",
        "postiveRatio = postiveRatio.reset_index()\n",
        "postiveRatio.columns = ['algo', 'avg_correlation_coefficient']\n",
        "postiveRatio['Sharpe Ratio'] = [0] * 6\n",
        "\n",
        "# postiveRatio.plot.bar(x = 'algo', y = 'avg_correlation_coefficient')\n",
        "\n",
        "postiveRatiom = pd.DataFrame(multi_performance_score.groupby(\"algo\").apply(lambda x : np.mean(x['score'])))\n",
        "postiveRatiom = postiveRatiom.reset_index()\n",
        "postiveRatiom.columns = ['algo', 'avg_correlation_coefficient']\n",
        "postiveRatiom['Sharpe Ratio'] = [0] * 6\n",
        "\n",
        "# postiveRatiom.plot.bar(x = 'algo', y = 'avg_correlation_coefficient')\n",
        "\n",
        "\n",
        "for algo in ['A2C', 'PPO', 'LR','DT', 'RF', 'SVM']:\n",
        "  postiveRatio.loc[postiveRatio['algo'] == algo, 'Sharpe Ratio'] = meta_score.loc[meta_score['Algorithm'] == algo,'Sharpe ratio'].values[0]\n",
        "  postiveRatiom.loc[postiveRatio['algo'] == algo, 'Sharpe Ratio'] = meta_score.loc[meta_score['Algorithm'] == algo,'Sharpe ratio'].values[0]\n",
        "\n",
        "postiveRatio.sort_values(\"Sharpe Ratio\", inplace= True)\n",
        "\n",
        "postiveRatiom.sort_values(\"Sharpe Ratio\", inplace= True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rLjcOmRBjeu"
      },
      "outputs": [],
      "source": [
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Create figure with secondary y-axis\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "# Add traces\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=postiveRatiom['algo'], y=postiveRatiom['Sharpe Ratio'], name=\"Sharpe Ratio\", marker_size = 15, line_width=5),\n",
        "    secondary_y=True,\n",
        ")\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Bar(x=postiveRatiom['algo'], y=postiveRatiom['avg_correlation_coefficient'], name=\"Multi-Step Average Correlation Coefficient          \", width\n",
        "    =0.38),\n",
        "    secondary_y=False,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Bar(x=postiveRatio['algo'], y=postiveRatio['avg_correlation_coefficient'], name=\"Single-Step Average Correlation Coefficient           \", width\n",
        "    =0.38),\n",
        "    secondary_y=False,\n",
        ")\n",
        "    \n",
        "fig.update_layout(\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=1.5,\n",
        "    xanchor=\"right\",\n",
        "    x=0.95\n",
        "))\n",
        "fig.update_layout(font_size = 15)\n",
        "\n",
        "# Set x-axis title\n",
        "fig.update_xaxes(title_text=\"Model\")\n",
        "fig.update_xaxes(showline=True, linecolor='black',showgrid=True,gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, secondary_y=False, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "# Set y-axes titles\n",
        "fig.update_yaxes(title_text=\"Average Correlation Coefficient\", secondary_y=False, range = [-0.1,0.1])\n",
        "fig.update_yaxes(title_text=\"Sharpe Ratio\", secondary_y=True,range = [-0.5,2.5])\n",
        "\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5vQar1zIACp"
      },
      "source": [
        "#### The correlation coefficient represents the level of prediction power. \n",
        "\n",
        "We found that:\n",
        ">*  The sharpe ratio is in accordance with both single-step and  multi-step average correlation coefficient.\n",
        ">* DRL agents is better at multi-step prediction than ML algorithms while worse at single-step prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaMzEa2UxmI6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "fig = make_subplots(rows=2, cols=3)\n",
        "\n",
        "# trace0 = go.Histogram(x=performance_score[performance_score['algo'] == 'A2C']['score'].values, nbinsx=25, name = 'A2C',histnorm='probability')\n",
        "# trace1 = go.Histogram(x=performance_score[performance_score['algo'] == 'PPO']['score'].values, nbinsx=25, name = 'PPO',histnorm='probability')\n",
        "# trace2 = go.Histogram(x=performance_score[performance_score['algo'] == 'DT']['score'].values, nbinsx=25, name = 'DT',histnorm='probability')\n",
        "# trace3 = go.Histogram(x=performance_score[performance_score['algo'] == 'LR']['score'].values, nbinsx=25, name = 'LR',histnorm='probability')\n",
        "# trace4 = go.Histogram(x=performance_score[performance_score['algo'] == 'SVM']['score'].values, nbinsx=25, name = 'SVM',histnorm='probability')\n",
        "# trace5 = go.Histogram(x=performance_score[performance_score['algo'] == 'RF']['score'].values, nbinsx=25, name = 'RF',histnorm='probability')\n",
        "\n",
        "\n",
        "# fig.append_trace(trace0, 1, 1)\n",
        "# fig.append_trace(trace1, 1, 2)\n",
        "# fig.append_trace(trace2, 1, 3)\n",
        "# fig.append_trace(trace3, 2, 1)\n",
        "# fig.append_trace(trace4, 2, 2)\n",
        "# fig.append_trace(trace5, 2, 3)\n",
        "# Update xaxis properties\n",
        "# fig.update_xaxes(title_text=\"Correlation coefficient\", row=2, col=2)\n",
        "# fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
        "# fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
        "\n",
        "# fig.update_layout(\n",
        "\n",
        "#     paper_bgcolor='rgba(1,1,0,0)',\n",
        "#     plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "#      font=dict(\n",
        "       \n",
        "#         size=18,\n",
        "#     ),\n",
        "\n",
        "# )\n",
        "# fig.update_layout(legend=dict(\n",
        "#     yanchor=\"top\",\n",
        "#     y=0.99,\n",
        "#     xanchor=\"left\",\n",
        "#     x=1\n",
        "# ))\n",
        "\n",
        "#fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "#fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "#fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwiYdXs2IgZl"
      },
      "source": [
        "#### Histogram of single-step correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyj3_rmFF42y"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "fig = make_subplots(rows=2, cols=3)\n",
        "\n",
        "trace0 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'A2C']['score'].values, nbinsx=25, name = 'A2C',histnorm='probability')\n",
        "trace1 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'PPO']['score'].values, nbinsx=25, name = 'PPO',histnorm='probability')\n",
        "trace2 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'DT']['score'].values, nbinsx=25, name = 'DT',histnorm='probability')\n",
        "trace3 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'LR']['score'].values, nbinsx=25, name = 'LR',histnorm='probability')\n",
        "trace4 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'SVM']['score'].values, nbinsx=25, name = 'SVM',histnorm='probability')\n",
        "trace5 = go.Histogram(x=multi_performance_score[multi_performance_score['algo'] == 'RF']['score'].values, nbinsx=25, name = 'RF',histnorm='probability')\n",
        "\n",
        "fig.update_layout(yaxis1 = dict(range=[0, 0.2]))\n",
        "fig.update_layout(yaxis2 = dict(range=[0, 0.2]))\n",
        "fig.update_layout(yaxis3 = dict(range=[0, 0.4]))\n",
        "fig.update_layout(yaxis4 = dict(range=[0, 0.4]))\n",
        "fig.update_layout(yaxis5 = dict(range=[0, 0.4]))\n",
        "fig.update_layout(yaxis6 = dict(range=[0, 0.4]))\n",
        "\n",
        "fig.append_trace(trace0, 1, 1)\n",
        "fig.append_trace(trace1, 1, 2)\n",
        "fig.append_trace(trace2, 1, 3)\n",
        "fig.append_trace(trace3, 2, 1)\n",
        "fig.append_trace(trace4, 2, 2)\n",
        "fig.append_trace(trace5, 2, 3)\n",
        "# Update xaxis properties\n",
        "fig.update_xaxes(title_text=\"Correlation coefficient\", row=2, col=2)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=1, col=1)\n",
        "fig.update_yaxes(title_text=\"Frequency\", row=2, col=1)\n",
        "\n",
        "fig.update_layout(\n",
        "\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "     font=dict(\n",
        "       \n",
        "        size=18,\n",
        "    ),\n",
        "\n",
        ")\n",
        "fig.update_layout(legend=dict(\n",
        "    yanchor=\"top\",\n",
        "    y=0.99,\n",
        "    xanchor=\"left\",\n",
        "    x=1\n",
        "))\n",
        "\n",
        "fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "\n",
        "fig.show(\"png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JQCKXP-ImaL"
      },
      "source": [
        "#### Histogram of multi-step correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX8bc_5n_DxX"
      },
      "outputs": [],
      "source": [
        "performance_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kgu6x66KuPaZ"
      },
      "outputs": [],
      "source": [
        "multi_performance_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ag31YxZ7uYs-"
      },
      "outputs": [],
      "source": [
        "a2c_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok3i8dmbunqm"
      },
      "outputs": [],
      "source": [
        "a2c_weights.to_csv(\"./pesos.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fJltIjCuwBp"
      },
      "outputs": [],
      "source": [
        "ppo_weights.to_csv(\"./pesos2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXLlq1HOwAJW"
      },
      "outputs": [],
      "source": [
        "lr_weights.to_csv(\"./lr.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8Syq5lc97fe"
      },
      "outputs": [],
      "source": [
        "dt_weights.to_csv(\"./dt.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k1CDdDh-DP8"
      },
      "outputs": [],
      "source": [
        "svm_weights.to_csv(\"./svm.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XhzjTQ--FJB"
      },
      "outputs": [],
      "source": [
        "rf_weights.to_csv(\"./rf.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6Yw-vxc-HXU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "zI0UkiCb2pLD",
        "NaCnRr2K4DuP"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}